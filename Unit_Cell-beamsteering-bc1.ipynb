{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e920c6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:45:50.699708Z",
     "start_time": "2025-05-09T01:45:50.464972Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')  # Use the TkAgg backend\n",
    "# import matplotlib.pyplot as plt\n",
    "# # Generate some data\n",
    "# x = [1, 2, 3, 4, 5]\n",
    "# y = [2, 4, 6, 8, 10]\n",
    "# # Create a line plot\n",
    "# plt.plot(x, y)\n",
    "# # Add labels and title\n",
    "# plt.xlabel('X-axis')\n",
    "# plt.ylabel('Y-axis')\n",
    "# plt.title('Line Plot')\n",
    "# # Display the plot\n",
    "# plt.show()\n",
    "# import os\n",
    "# import signal\n",
    "# import psutil\n",
    "\n",
    "# def kill_python_processes():\n",
    "#     for proc in psutil.process_iter(['pid', 'name', 'cmdline']):\n",
    "#         if proc.info['name'] == 'python' and 'cuda' in ' '.join(proc.info['cmdline']):\n",
    "#             os.kill(proc.info['pid'], signal.SIGTERM)\n",
    "# # Call the function to kill the Python processes\n",
    "# kill_python_processes()\n",
    "# import os\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eac11ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:45:51.218090Z",
     "start_time": "2025-05-09T01:45:51.200295Z"
    },
    "code_folding": [
     0,
     107
    ]
   },
   "outputs": [],
   "source": [
    "def bipolar(lutsize=256, neutral=1/3, interp=None):\n",
    "    \"\"\"\n",
    "    Bipolar hot/cold colormap, with neutral central color.\n",
    "\n",
    "    This colormap is meant for visualizing diverging data; positive\n",
    "    and negative deviations from a central value.  It is similar to a \"hot\"\n",
    "    blackbody colormap for positive values, but with a complementary\n",
    "    \"cold\" colormap for negative values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lutsize : int\n",
    "        The number of elements in the colormap lookup table. (Default is 256.)\n",
    "    neutral : float\n",
    "        The gray value for the neutral middle of the colormap.  (Default is\n",
    "        1/3.)\n",
    "        The colormap goes from cyan-blue-neutral-red-yellow if neutral\n",
    "        is < 0.5, and from blue-cyan-neutral-yellow-red if `neutral` > 0.5.\n",
    "        For shaded 3D surfaces, a `neutral` near 0.5 is better, because it\n",
    "        minimizes luminance changes that would otherwise obscure shading cues\n",
    "        for determining 3D structure.\n",
    "        For 2D heat maps, a `neutral` near the 0 or 1 extremes is better, for\n",
    "        maximizing luminance change and showing details of the data.\n",
    "    interp : str or int, optional\n",
    "        Specifies the type of interpolation.\n",
    "        ('linear', 'nearest', 'zero', 'slinear', 'quadratic, 'cubic')\n",
    "        or as an integer specifying the order of the spline interpolator\n",
    "        to use. Default is 'linear' for dark neutral and 'cubic' for light\n",
    "        neutral.  See `scipy.interpolate.interp1d`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : matplotlib.colors.LinearSegmentedColormap\n",
    "        The resulting colormap object\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from mpl_toolkits.mplot3d import Axes3D\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> import numpy as np\n",
    "    >>> from bipolar import bipolar\n",
    "\n",
    "    >>> x = y = np.arange(-4, 4, 0.15)\n",
    "    >>> x, y = np.meshgrid(x, y)\n",
    "    >>> z = (1 - x/2 + x**5 + y**3) * np.exp(-x**2 - y**2)\n",
    "\n",
    "    >>> fig, axs = plt.subplots(2, 2, figsize=(12, 8),\n",
    "    ...                         subplot_kw={'projection': '3d'})\n",
    "    >>> for ax, neutral in (((0, 0), 1/3),  # Default\n",
    "    ...                     ((0, 1), 0.1),  # Dark gray as neutral\n",
    "    ...                     ((1, 0), 0.9),  # Light gray as neutral\n",
    "    ...                     ((1, 1), 2/3),\n",
    "    ...                     ):\n",
    "    ...     surf = axs[ax].plot_surface(x, y, z, rstride=1, cstride=1,\n",
    "    ...                                 vmax=abs(z).max(), vmin=-abs(z).max(),\n",
    "    ...                                 cmap=bipolar(neutral=neutral))\n",
    "    >>>     axs[ax].set_title(f'{neutral:.3f}')\n",
    "    ...     fig.colorbar(surf, ax=axs[ax])\n",
    "    >>> plt.show()\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Lehmann Manja, Crutch SJ, Ridgway GR et al. \"Cortical thickness\n",
    "        and voxel-based morphometry in posterior cortical atrophy and typical\n",
    "        Alzheimer's disease\", Neurobiology of Aging, 2009,\n",
    "        doi:10.1016/j.neurobiolaging.2009.08.017\n",
    "\n",
    "    \"\"\"\n",
    "    n = neutral\n",
    "    if 0 <= n <= 0.5:\n",
    "        if interp is None:\n",
    "            # Seems to work well with dark neutral colors\n",
    "            interp = 'linear'\n",
    "\n",
    "        data = (\n",
    "            (0, 1, 1),  # cyan\n",
    "            (0, 0, 1),  # blue\n",
    "            (n, n, n),  # dark neutral\n",
    "            (1, 0, 0),  # red\n",
    "            (1, 1, 0),  # yellow\n",
    "        )\n",
    "    elif 0.5 < n <= 1:\n",
    "        if interp is None:\n",
    "            # Seems to work better with bright neutral colors\n",
    "            # Produces bright yellow or cyan rings otherwise\n",
    "            interp = 'cubic'\n",
    "\n",
    "        data = (\n",
    "            (0, 0, 1),  # blue\n",
    "            (0, 1, 1),  # cyan\n",
    "            (n, n, n),  # light neutral\n",
    "            (1, 1, 0),  # yellow\n",
    "            (1, 0, 0),  # red\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError('n must be 0.0 < n < 1.0')\n",
    "\n",
    "    xi = np.linspace(0, 1, len(data))\n",
    "    cm_interp = scipy.interpolate.interp1d(xi, data, axis=0, kind=interp)\n",
    "    xnew = np.linspace(0, 1, lutsize)\n",
    "    ynew = cm_interp(xnew)\n",
    "\n",
    "    # Non-linear interpolation exceeds the RGB cube\n",
    "    ynew = np.clip(ynew, 0, 1)\n",
    "\n",
    "    return cm.colors.LinearSegmentedColormap.from_list('bipolar', ynew,\n",
    "                                                       lutsize)\n",
    "def hotcold(lutsize=256, neutral=1/3, interp=None):\n",
    "    \"\"\"\n",
    "    Bipolar hot/cold colormap, with neutral central color.\n",
    "\n",
    "    This colormap is meant for visualizing diverging data; positive\n",
    "    and negative deviations from a central value.  It is similar to a \"hot\"\n",
    "    blackbody colormap for positive values, but with a complementary\n",
    "    \"cold\" colormap for negative values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lutsize : int\n",
    "        The number of elements in the colormap lookup table. (Default is 256.)\n",
    "    neutral : float\n",
    "        The gray value for the neutral middle of the colormap.  (Default is\n",
    "        1/3.)\n",
    "        The colormap goes from cyan-blue-neutral-red-yellow if neutral\n",
    "        is < 0.5, and from blue-cyan-neutral-yellow-red if `neutral` > 0.5.\n",
    "        For shaded 3D surfaces, a `neutral` near 0.5 is better, because it\n",
    "        minimizes luminance changes that would otherwise obscure shading cues\n",
    "        for determining 3D structure.\n",
    "        For 2D heat maps, a `neutral` near the 0 or 1 extremes is better, for\n",
    "        maximizing luminance change and showing details of the data.\n",
    "    interp : str or int, optional\n",
    "        Specifies the type of interpolation.\n",
    "        ('linear', 'nearest', 'zero', 'slinear', 'quadratic, 'cubic')\n",
    "        or as an integer specifying the order of the spline interpolator\n",
    "        to use. Default is 'linear' for dark neutral and 'cubic' for light\n",
    "        neutral.  See `scipy.interpolate.interp1d`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : matplotlib.colors.LinearSegmentedColormap\n",
    "        The resulting colormap object\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from mpl_toolkits.mplot3d import Axes3D\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> import numpy as np\n",
    "    >>> from bipolar import hotcold\n",
    "\n",
    "    >>> x = y = np.arange(-4, 4, 0.15)\n",
    "    >>> x, y = np.meshgrid(x, y)\n",
    "    >>> z = (1 - x/2 + x**5 + y**3) * np.exp(-x**2 - y**2)\n",
    "\n",
    "    >>> fig, axs = plt.subplots(2, 2, figsize=(12, 8),\n",
    "    ...                         subplot_kw={'projection': '3d'})\n",
    "    >>> for ax, neutral in (((0, 0), 1/3),  # Default\n",
    "    ...                     ((0, 1), 0.1),  # Dark gray as neutral\n",
    "    ...                     ((1, 0), 0.9),  # Light gray as neutral\n",
    "    ...                     ((1, 1), 2/3),\n",
    "    ...                     ):\n",
    "    ...     surf = axs[ax].plot_surface(x, y, z, rstride=1, cstride=1,\n",
    "    ...                                 vmax=abs(z).max(), vmin=-abs(z).max(),\n",
    "    ...                                 cmap=hotcold(neutral=neutral))\n",
    "    >>>     axs[ax].set_title(f'{neutral:.3f}')\n",
    "    ...     fig.colorbar(surf, ax=axs[ax])\n",
    "    >>> plt.show()\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Lehmann Manja, Crutch SJ, Ridgway GR et al. \"Cortical thickness\n",
    "        and voxel-based morphometry in posterior cortical atrophy and typical\n",
    "        Alzheimer's disease\", Neurobiology of Aging, 2009,\n",
    "        doi:10.1016/j.neurobiolaging.2009.08.017\n",
    "\n",
    "    \"\"\"\n",
    "    n = neutral\n",
    "    if 0 <= n <= 0.5:\n",
    "        if interp is None:\n",
    "            # Seems to work well with dark neutral colors\n",
    "            interp = 'linear'\n",
    "\n",
    "        data = (\n",
    "            (0, 1, 1),  # cyan\n",
    "            (0, 0, 1),  # blue\n",
    "            (n, n, n),  # dark neutral\n",
    "            (1, 0, 0),  # red\n",
    "            (1, 1, 0),  # yellow\n",
    "        )\n",
    "    elif 0.5 < n <= 1:\n",
    "        if interp is None:\n",
    "            # Seems to work better with bright neutral colors\n",
    "            # Produces bright yellow or cyan rings otherwise\n",
    "            interp = 'cubic'\n",
    "\n",
    "        data = (\n",
    "            (0, 0, 1),  # blue\n",
    "            (0, 1, 1),  # cyan\n",
    "            (n, n, n),  # light neutral\n",
    "            (1, 1, 0),  # yellow\n",
    "            (1, 0, 0),  # red\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError('n must be 0.0 < n < 1.0')\n",
    "\n",
    "    t = np.linspace(0, 1, lutsize//2)\n",
    "\n",
    "    # Super ugly Bezier curve\n",
    "    # Do 2, one for each half, from nnn to 100 and from 001 to nnn\n",
    "\n",
    "    x1 = data[2][0]\n",
    "    y1 = data[2][1]\n",
    "    z1 = data[2][2]\n",
    "\n",
    "    xc = data[1][0]\n",
    "    yc = data[1][1]\n",
    "    zc = data[1][2]\n",
    "\n",
    "    x2 = data[0][0]\n",
    "    y2 = data[0][1]\n",
    "    z2 = data[0][2]\n",
    "\n",
    "    w = 1  # weight\n",
    "\n",
    "    r1 = (((1 - t)**2*x1 + 2*(1 - t)*t*w*xc + t**2*x2) /\n",
    "          ((1 - t)**2 + 2*(1 - t)*t*w + t**2))\n",
    "    g1 = (((1 - t)**2*y1 + 2*(1 - t)*t*w*yc + t**2*y2) /\n",
    "          ((1 - t)**2 + 2*(1 - t)*t*w + t**2))\n",
    "    b1 = (((1 - t)**2*z1 + 2*(1 - t)*t*w*zc + t**2*z2) /\n",
    "          ((1 - t)**2 + 2*(1 - t)*t*w + t**2))\n",
    "\n",
    "    x1 = data[2][0]\n",
    "    y1 = data[2][1]\n",
    "    z1 = data[2][2]\n",
    "\n",
    "    xc = data[3][0]\n",
    "    yc = data[3][1]\n",
    "    zc = data[3][2]\n",
    "\n",
    "    x2 = data[4][0]\n",
    "    y2 = data[4][1]\n",
    "    z2 = data[4][2]\n",
    "\n",
    "    r2 = (((1 - t)**2*x1 + 2*(1 - t)*t*w*xc + t**2*x2) /\n",
    "          ((1 - t)**2 + 2*(1 - t)*t*w + t**2))\n",
    "    g2 = (((1 - t)**2*y1 + 2*(1 - t)*t*w*yc + t**2*y2) /\n",
    "          ((1 - t)**2 + 2*(1 - t)*t*w + t**2))\n",
    "    b2 = (((1 - t)**2*z1 + 2*(1 - t)*t*w*zc + t**2*z2) /\n",
    "          ((1 - t)**2 + 2*(1 - t)*t*w + t**2))\n",
    "\n",
    "    rgb1 = np.dstack((r1, g1, b1))[0]\n",
    "    rgb2 = np.dstack((r2, g2, b2))[0]\n",
    "\n",
    "    ynew = np.concatenate((rgb1[1:][::-1], rgb2))\n",
    "\n",
    "    return cm.colors.LinearSegmentedColormap.from_list('hotcold', ynew,\n",
    "                                                       lutsize)\n",
    "# if __name__ == \"__main__\":\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     def func3(x, y):\n",
    "#         return (1 - x/2 + x**5 + y**3) * np.exp(-x**2 - y**2)\n",
    "\n",
    "#     # Make these smaller to increase the resolution\n",
    "#     dx, dy = 0.02, 0.02\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "\n",
    "#     x = np.arange(-3.0, 3.0001, dx)\n",
    "#     y = np.arange(-3.0, 3.0001, dy)\n",
    "#     X, Y = np.meshgrid(x, y)\n",
    "\n",
    "#     Z = func3(X, Y)\n",
    "#     cmap = hotcold(neutral=1/2, interp='linear', lutsize=2048)\n",
    "#     plt.pcolor(X, Y, Z, cmap=cmap, vmax=abs(Z).max(), vmin=-abs(Z).max())\n",
    "#     plt.colorbar()\n",
    "#     plt.axis([-3, 3, -3, 3])\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3926aec3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:45:53.874087Z",
     "start_time": "2025-05-09T01:45:51.694879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import rcwa_utils\n",
    "import tensor_utils\n",
    "from tensor_utils import EigGeneral\n",
    "import matplotlib.font_manager as font_manager\n",
    "import matplotlib.cm as cm\n",
    "import solver\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import matplotlib.font_manager as fm\n",
    "import scipy.optimize as optimize\n",
    "import scipy.interpolate\n",
    "from matplotlib import cm\n",
    "import os\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from scipy.special import erf\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\"\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.set_printoptions(precision=8)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")#torch.cuda.set_device(1)\n",
    "    print(\"GPU available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6b7d1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:45:53.889015Z",
     "start_time": "2025-05-09T01:45:53.875270Z"
    },
    "code_folding": [
     10,
     16,
     41,
     84
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_material_file(filename):\n",
    "    data = np.loadtxt(filename, delimiter=',')\n",
    "    wavelengths = data[:, 0]\n",
    "    n_values = data[:, 1]\n",
    "    k_values = data[:, 2]\n",
    "    return wavelengths, n_values, k_values\n",
    "\n",
    "def calculate_epsilon(n, k):\n",
    "    epsilon_r = n**2 - k**2\n",
    "    epsilon_i = 2 * n * k\n",
    "    epsilon = epsilon_r + 1j * epsilon_i\n",
    "    return epsilon\n",
    "\n",
    "def interpolate_material(wavelengths, n_values, k_values, wavelength):\n",
    "    n = np.interp(wavelength, wavelengths, n_values)\n",
    "    k = np.interp(wavelength, wavelengths, k_values)\n",
    "    epsilon = calculate_epsilon(n, k)\n",
    "    return n, k, epsilon\n",
    "\n",
    "# def interpolate_material(wavelengths, n_values, k_values, wavelength):\n",
    "#     wavelengths_tensor = torch.tensor(wavelengths, dtype=torch.float64).to(\"cuda\")\n",
    "#     n_values_tensor = torch.tensor(n_values, dtype=torch.float64).to(\"cuda\")\n",
    "#     k_values_tensor = torch.tensor(k_values, dtype=torch.float64).to(\"cuda\")\n",
    "#     wavelength_tensor = torch.tensor(wavelength, dtype=torch.float64).to(\"cuda\")\n",
    "\n",
    "#     # Reshape tensors for interpolation\n",
    "#     wavelengths_tensor = wavelengths_tensor.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, num_points)\n",
    "#     n_values_tensor = n_values_tensor.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, num_points)\n",
    "#     k_values_tensor = k_values_tensor.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, num_points)\n",
    "#     wavelength_tensor = wavelength_tensor.unsqueeze(0)  # Shape: (1,)\n",
    "\n",
    "    # Perform linear interpolation\n",
    "    n = F.interpolate(n_values_tensor, size=1, mode='linear', align_corners=False)\n",
    "    k = F.interpolate(k_values_tensor, size=1, mode='linear', align_corners=False)\n",
    "    epsilon = calculate_epsilon(n.squeeze().item(), k.squeeze().item())\n",
    "\n",
    "    return n.item(), k.item(), epsilon\n",
    "\n",
    "def plot_material(wavelengths, n_values, k_values, eps_real, eps_imag, save_as):\n",
    "    # Increase font size\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    # Set serif font\n",
    "    plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "    # Plot n and k values\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(wavelengths, n_values, 'ro', label='n (data points)', linewidth=2)\n",
    "    plt.plot(wavelengths, k_values, 'go', label='k (data points)', linewidth=2)\n",
    "\n",
    "    # Interpolate n and k values\n",
    "    interp_wavelengths = np.linspace(min(wavelengths), max(wavelengths), 1000)\n",
    "    interp_n = np.interp(interp_wavelengths, wavelengths, n_values)\n",
    "    interp_k = np.interp(interp_wavelengths, wavelengths, k_values)\n",
    "    plt.plot(interp_wavelengths, interp_n, 'b-', label='n (interpolation)', linewidth=3)\n",
    "    plt.plot(interp_wavelengths, interp_k, 'c-', label='k (interpolation)', linewidth=3)\n",
    "\n",
    "    plt.xlabel('λ (nm)')\n",
    "    plt.ylabel('n, k')\n",
    "    plt.legend()\n",
    "    plt.title('Optical Constants')\n",
    "    plt.xlim(min(wavelengths), max(wavelengths))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_as + '_nk.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate and plot epsilon\n",
    "    epsilon_real = np.real(calculate_epsilon(interp_n, interp_k))\n",
    "    epsilon_imag = np.imag(calculate_epsilon(interp_n, interp_k))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(interp_wavelengths, epsilon_real, 'b', label='Re(ε)', linewidth=4)\n",
    "    plt.plot(interp_wavelengths, epsilon_imag, 'r', label='Im(ε)', linewidth=4)\n",
    "    plt.xlabel('λ (nm)')\n",
    "    plt.ylabel('ε')\n",
    "    plt.legend()\n",
    "    plt.title('Complex Permittivity')\n",
    "    plt.xlim(min(wavelengths), max(wavelengths))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_as + '_epsilon.pdf')\n",
    "    plt.show()\n",
    "    return epsilon_real,epsilon_imag\n",
    "\n",
    "def material_plotter(filename, start_wavelength, end_wavelength, resolution):\n",
    "    wavelengths, n_values, k_values = read_material_file(filename)\n",
    "    epsilon_real,epsilon_imag = plot_material(wavelengths, n_values, k_values, None, None, filename.split('.')[0])\n",
    "    return epsilon_real,epsilon_imag\n",
    "# Example usage\n",
    "# epsilon_real_am,epsilon_imag_am = material_plotter('material/AM_SB2_S3.txt', 0.4, 0.5, 1000)\n",
    "# epsilon_real_cr,epsilon_imag_cr = material_plotter('material/CR_SB2_S3.txt', 0.4, 0.5, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "674ae010",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:45:53.904226Z",
     "start_time": "2025-05-09T01:45:53.890020Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def calculate_effective_permittivity(Lc, epsilon_c, epsilon_a):\n",
    "    \"\"\"\n",
    "    Calculate the effective permittivity of partially crystallized GST by solving the equation numerically using the bisection method.\n",
    "\n",
    "    Args:\n",
    "    - Lc: Crystallization fraction of GST, ranging from 0 (amorphous) to 1 (fully crystalline).\n",
    "    - epsilon_c: Permittivity of crystalline GST.\n",
    "    - epsilon_a: Permittivity of amorphous GST.\n",
    "    - tol: Tolerance for convergence (default: 1e-2).\n",
    "\n",
    "    Returns:\n",
    "    - Effective permittivity (εeff).\n",
    "    \"\"\"\n",
    "    right_side = (Lc-1)*(1-epsilon_a) / (2+epsilon_a)+(Lc * ((epsilon_c - 1) / (epsilon_c + 2)))\n",
    "    epsilon_eff = ((2*right_side)+1)/(1-right_side)\n",
    "    return epsilon_eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b33e370b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:45:53.920227Z",
     "start_time": "2025-05-09T01:45:53.906230Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# wavelengths, n_values_am, k_values_am = read_material_file('material\\AM_SB2_S3.txt')\n",
    "# wavelength = .785 # Specify the wavelength for interpolation\n",
    "# n_am, k_am, epsilon_am = interpolate_material(wavelengths, n_values_am, k_values_am, wavelength)\n",
    "# print(f\"Amorphous: For wavelength {wavelength} nm, n = {n_am}, k = {k_am}, epsilon = {epsilon_am}\")\n",
    "# wavelengths, n_values_cr, k_values_cr = read_material_file('material\\CR_SB2_S3.txt')\n",
    "# n_cr, k_cr, epsilon_cr = interpolate_material(wavelengths, n_values_cr, k_values_cr, wavelength)\n",
    "# print(f\"Crystalline: For wavelength {wavelength} nm, n = {n_cr}, k = {k_cr}, epsilon = {epsilon_cr}\")\n",
    "# Lc = 0.5\n",
    "# epsilon_eff = calculate_effective_permittivity(Lc, epsilon_cr, epsilon_am)\n",
    "# print(f\"Crystalline: For wavelength {wavelength} nm, L_c {Lc}, epsilon = {epsilon_eff}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f65853d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:45:53.935550Z",
     "start_time": "2025-05-09T01:45:53.920399Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:39: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:39: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\jchang427\\AppData\\Local\\Temp\\ipykernel_10052\\472947706.py:39: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  plt.savefig('material\\plot_effective_permittivity.pdf')\n"
     ]
    }
   ],
   "source": [
    "def plot_effective_permittivity(epsilon_am, epsilon_Cr):\n",
    "    \"\"\"\n",
    "    Plot the effective permittivity (εeff) for different crystallization percentages.\n",
    "\n",
    "    Args:\n",
    "    - epsilon_am: Permittivity of amorphous GST.\n",
    "    - epsilon_Cr: Permittivity of crystalline GST.\n",
    "\n",
    "    Returns:\n",
    "    None (plots the results and saves as a PDF).\n",
    "    \"\"\"\n",
    "\n",
    "    # Increase font size\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    # Set serif font\n",
    "    plt.rcParams['font.family'] = 'serif'\n",
    "    # Increase the plot size\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    Lc_values = np.linspace(0, 1, 100)\n",
    "    epsilon_real_eff = []\n",
    "    epsilon_imag_eff = []\n",
    "\n",
    "    for Lc in Lc_values:\n",
    "        epsilon_eff = calculate_effective_permittivity(Lc, epsilon_Cr, epsilon_am)\n",
    "        epsilon_real_eff.append(np.real(epsilon_eff))\n",
    "        epsilon_imag_eff.append(np.imag(epsilon_eff))\n",
    "\n",
    "    # Plot the results\n",
    "    plt.plot(Lc_values * 100, epsilon_real_eff, 'b-', label='Re(εeff)', linewidth=4)\n",
    "    plt.plot(Lc_values * 100, epsilon_imag_eff, 'c-', label='Im(εeff)', linewidth=4)\n",
    "    plt.xlabel('Crystallization %', fontsize=16)\n",
    "    plt.ylabel('εeff', fontsize=16)\n",
    "    plt.legend( fontsize=14)\n",
    "    plt.title('Effective Permittivity', fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.xlim(min(Lc_values* 100), max(Lc_values* 100))\n",
    "    # Save the plot as PDF\n",
    "    plt.savefig('material\\plot_effective_permittivity.pdf')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "# plot_effective_permittivity(epsilon_am, epsilon_cr)="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0de7f90f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:45:53.951264Z",
     "start_time": "2025-05-09T01:45:53.937550Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:26: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:28: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:58: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:86: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<>:26: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:28: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:58: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:86: SyntaxWarning: invalid escape sequence '\\e'\n",
      "C:\\Users\\jchang427\\AppData\\Local\\Temp\\ipykernel_10052\\4197620705.py:26: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  wavelengths, n_values_am, k_values_am = read_material_file('material\\AM_SB2_S3.txt')\n",
      "C:\\Users\\jchang427\\AppData\\Local\\Temp\\ipykernel_10052\\4197620705.py:28: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  wavelengths, n_values, k_values = read_material_file('material\\CR_SB2_S3.txt')\n",
      "C:\\Users\\jchang427\\AppData\\Local\\Temp\\ipykernel_10052\\4197620705.py:58: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  plt.savefig('material\\materialepsilon_real_vs_wavelength.pdf')\n",
      "C:\\Users\\jchang427\\AppData\\Local\\Temp\\ipykernel_10052\\4197620705.py:86: SyntaxWarning: invalid escape sequence '\\e'\n",
      "  plt.savefig('material\\epsilon_imag_vs_wavelength.pdf')\n"
     ]
    }
   ],
   "source": [
    "def plot_epsilon_vs_wavelength_range(wavelengths, Lc_values):\n",
    "    \"\"\"\n",
    "    Plot the real and imaginary parts of permittivity (ε) for different Lc values as a function of wavelength in a specified range.\n",
    "\n",
    "    Args:\n",
    "    - wavelengths: Array of wavelengths.\n",
    "    - n_values: Array of refractive indices.\n",
    "    - k_values: Array of extinction coefficients.\n",
    "    - Lc_values: Array of Lc values.\n",
    "\n",
    "    Returns:\n",
    "    None (plots the results).\n",
    "    \"\"\"   \n",
    "    # Increase font size\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    # Set serif font\n",
    "    plt.rcParams['font.family'] = 'serif'\n",
    "    Lc_values = np.linspace(0, 1, 11)\n",
    "    # Specify the wavelength range\n",
    "    wavelength_range = np.linspace(0.4, 1.6, 400)\n",
    "    # Initialize arrays to store epsilon values\n",
    "    epsilon_real = np.zeros((len(Lc_values),len(wavelength_range)))\n",
    "    epsilon_imag = np.zeros((len(Lc_values),len(wavelength_range)))\n",
    "    for i, Lc in enumerate(Lc_values):\n",
    "        for j, wavelength in enumerate(wavelength_range):\n",
    "            wavelengths, n_values_am, k_values_am = read_material_file('material\\AM_SB2_S3.txt')\n",
    "            n_am, k_am, epsilon_am = interpolate_material(wavelengths, n_values_am, k_values_am, wavelength)\n",
    "            wavelengths, n_values, k_values = read_material_file('material\\CR_SB2_S3.txt')  \n",
    "            n_cr, k_cr, epsilon_cr = interpolate_material(wavelengths, n_values_cr, k_values_cr, wavelength)\n",
    "            epsilon_eff = calculate_effective_permittivity(Lc, epsilon_cr, epsilon_am)\n",
    "            epsilon_real[i, j] = np.real(epsilon_eff)\n",
    "            epsilon_imag[i, j] = np.imag(epsilon_eff)\n",
    "    # Plot epsilon vs wavelength for different Lc values - Real part\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    cmap = bipolar(neutral=0.2, interp='linear', lutsize=2048)\n",
    "\n",
    "    colors =cmap(np.linspace(0, 1, len(Lc_values)))\n",
    "\n",
    "    for i, Lc in enumerate(Lc_values):\n",
    "        ax.plot(wavelength_range, epsilon_real[i], color=colors[i], linestyle='-', label=f'Re(ε) - Lc={Lc:.2f}')\n",
    "\n",
    "    ax.set_xlabel('λ (nm)', fontsize=16)\n",
    "    ax.set_ylabel('Permittivity (ε)', fontsize=16)\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.set_title('Real Part of Effective Permittivity vs Wavelength', fontsize=18)\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.xlim(min(wavelength_range), max(wavelength_range))\n",
    "\n",
    "    # Create a colorbar\n",
    "    norm = plt.Normalize(0, 1)\n",
    "    sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax)\n",
    "    cbar.set_label('Lc', fontsize=14)\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig('material\\materialepsilon_real_vs_wavelength.pdf')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Plot epsilon vs wavelength for different Lc values - Imaginary part\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    colors = cmap(np.linspace(0, 1, len(Lc_values)))\n",
    "\n",
    "    for i, Lc in enumerate(Lc_values):\n",
    "        ax.plot(wavelength_range, epsilon_imag[i], color=colors[i], linestyle='-', label=f'Im(ε) - Lc={Lc:.2f}')\n",
    "\n",
    "    ax.set_xlabel('λ (nm)', fontsize=16)\n",
    "    ax.set_ylabel('Permittivity (ε)', fontsize=16)\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.set_title('Imaginary Part of Effective Permittivity vs Wavelength', fontsize=18)\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.xlim(min(wavelength_range), max(wavelength_range))\n",
    "\n",
    "    # Create a colorbar\n",
    "    norm = plt.Normalize(0, 1)\n",
    "    sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax)\n",
    "    cbar.set_label('Lc', fontsize=14)\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig('material\\epsilon_imag_vs_wavelength.pdf')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "# Specify the Lc values\n",
    "# Lc_values = np.linspace(0, 1, 11)\n",
    "# Call the function to plot epsilon vs wavelength for the specified range and Lc values\n",
    "# plot_epsilon_vs_wavelength_range(wavelengths, Lc_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd835412",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:45:53.964160Z",
     "start_time": "2025-05-09T01:45:53.953263Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plotter(Reflection, wavelength_mat, ylabel, output_filename, color='blue'):\n",
    "    # Increase font size\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    # Set serif font\n",
    "    plt.rcParams['font.family'] = 'serif'\n",
    "    # Create a line plot with the specified color\n",
    "    plt.plot(wavelength_mat, Reflection, color=color, linewidth=3)\n",
    "    # Set labels and title\n",
    "    plt.xlabel('λ (nm)')\n",
    "    plt.ylabel(ylabel)\n",
    "    # Set plot limits\n",
    "    plt.xlim(min(wavelength_mat), max(wavelength_mat))\n",
    "    # Adjust figure labels within the plot\n",
    "    plt.tight_layout()\n",
    "    # Save the plot as a PDF file\n",
    "    plt.savefig(output_filename)\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "264a7543",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:45:54.150183Z",
     "start_time": "2025-05-09T01:45:54.127363Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plotter_iteration(Reflection, wavelength_mat, ylabel, output_filename, color='blue'):\n",
    "    # Increase font size\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    # Set serif font\n",
    "    plt.rcParams['font.family'] = 'serif'\n",
    "    # Create a line plot with the specified color\n",
    "    plt.plot(wavelength_mat, Reflection, color=color, linewidth=3)\n",
    "    # Set labels and title\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel(ylabel)\n",
    "    # Set plot limits\n",
    "    plt.xlim(min(wavelength_mat), max(wavelength_mat))\n",
    "    # Adjust figure labels within the plot\n",
    "    plt.tight_layout()\n",
    "    # Save the plot as a PDF file\n",
    "    plt.savefig(output_filename)\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c125926f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:45:54.294681Z",
     "start_time": "2025-05-09T01:45:54.286634Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_combined(Lx, ER_t, Reflection, wavelength_mat, output_file):\n",
    "    # Get the dimensions of the real_part array\n",
    "    height, width = ER_t.shape[-2:]\n",
    "\n",
    "    # Calculate the coordinate range\n",
    "    x_range = np.linspace(-width/2, width/2, width)\n",
    "    y_range = np.linspace(-height/2, height/2, height)\n",
    "    x_range = np.multiply(x_range, Lx/width)*1e9\n",
    "    y_range = np.multiply(y_range, Lx/height)*1e9\n",
    "\n",
    "    # Calculate the magnitude of ER_t\n",
    "    magnitude = np.sqrt(np.abs(ER_t))\n",
    "\n",
    "    # Create the figure and subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Plot the refractive index profile\n",
    "    cmap = 'inferno'\n",
    "    im1 = ax1.imshow(magnitude[0,0,0,0], extent=[x_range[0], x_range[-1], y_range[0], y_range[-1]], cmap=cmap, origin='lower')\n",
    "    ax1.set_xlabel('x (nm)', fontsize=18)\n",
    "    ax1.set_ylabel('y (nm)', fontsize=18)\n",
    "    ax1.set_title('Refractive Index Profile', fontsize=18)\n",
    "    ax1.tick_params(labelsize=16)\n",
    "    fig.colorbar(im1, ax=ax1)\n",
    "\n",
    "    # Plot the Reflection vs. Wavelength\n",
    "    ax2.plot(wavelength_mat, Reflection, color='blue', linewidth=3)\n",
    "    ax2.set_xlabel('λ (nm)')\n",
    "    ax2.set_ylabel('Reflection')\n",
    "    ax2.set_xlim(min(wavelength_mat), max(wavelength_mat))\n",
    "    ax2.tick_params(labelsize=14)\n",
    "\n",
    "    # Adjust figure labels within the plot\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs('images', exist_ok=True)\n",
    "    output_path = os.path.join('images', output_file)\n",
    "    plt.savefig(output_path)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c790b557",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:45:54.474867Z",
     "start_time": "2025-05-09T01:45:54.462397Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_real_part_effective_permittivity(Lx,ER_t, output_file):\n",
    "    index = 0  # Specify the index of the Lc value you want to visualize\n",
    "    real_part = ER_t[0, 0, 0, 0, :, :].real.cpu().detach().numpy()\n",
    "    imag_part = ER_t[0, 0, 0, 1, :, :].real.cpu().detach().numpy()\n",
    "    n = 0.5 * np.sqrt(np.sqrt(imag_part**2 + real_part**2) + real_part)\n",
    "    \n",
    "    # Get the dimensions of the real_part array\n",
    "    height, width = real_part.shape\n",
    "\n",
    "    # Calculate the coordinate range\n",
    "    x_range = np.linspace(-width/2, width/2, width)\n",
    "    y_range = np.linspace(-height/2, height/2, height)\n",
    "    x_range = np.multiply(x_range,Lx/width)*1e9\n",
    "    y_range = np.multiply(y_range,Lx/height)*1e9\n",
    "\n",
    "    # Increase font size\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    # Set serif font\n",
    "    plt.rcParams['font.family'] = 'serif'\n",
    "    cmap = 'inferno'\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Plot the refractive index profile with centered axes\n",
    "    plt.imshow(n, extent=[x_range[0], x_range[-1], y_range[0], y_range[-1]], cmap = cmap,origin='lower')\n",
    "#     plt.colorbar()\n",
    "    plt.xlabel('x (nm)', fontsize=18)\n",
    "    plt.ylabel('y (nm)', fontsize=18)\n",
    "    plt.title('Refractive Index Profile', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs('images', exist_ok=True)\n",
    "    output_path = os.path.join('images', output_file)\n",
    "    plt.savefig(output_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e46444ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:45:54.633639Z",
     "start_time": "2025-05-09T01:45:54.618954Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_real_part_effective_permittivity_and_FOM(FOM, iteration, Lx, ER_t, output_file,\n",
    "                                                  relative_Transmission, relative_Phase_delay,\n",
    "                                                 desired_phase_1,desired_phase_2,\n",
    "                                                 desired_amp_1,desired_amp_2):\n",
    "    index = 0  # Specify the index of the Lc value you want to visualize\n",
    "    real_part = ER_t[0, 0, 0, 0, :, :].real.cpu().detach().numpy()\n",
    "    imag_part = ER_t[0, 0, 0, 1, :, :].real.cpu().detach().numpy()\n",
    "    n = 0.5 * np.sqrt(np.sqrt(imag_part**2 + real_part**2) + real_part)\n",
    "    # Define subplot positions\n",
    "#     pos0 = [0.05, 0.1, 0.28, 0.8]\n",
    "#     pos1 = [0.37, 0.1, 0.28, 0.8]\n",
    "#     pos2 = [0.69, 0.1, 0.28, 0.8]\n",
    "    # Get the dimensions of the real_part array\n",
    "    height, width = real_part.shape\n",
    "\n",
    "    # Calculate the coordinate range\n",
    "    x_range = np.linspace(-width/2, width/2, width)\n",
    "    y_range = np.linspace(-height/2, height/2, height)\n",
    "    x_range = np.multiply(x_range, Lx/width) * 1e9\n",
    "    y_range = np.multiply(y_range, Lx/height) * 1e9\n",
    "    # Create the figure\n",
    "#     fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Create subplots with the defined positions\n",
    "#     axs0 = fig.add_axes(pos0)\n",
    "#     axs1 = fig.add_axes(pos1, projection='polar')\n",
    "#     axs2 = fig.add_axes(pos2)\n",
    "\n",
    "    # Plot data on axs0 (FOM vs Iteration)\n",
    "    axs0.plot(iteration, FOM, color='red', linewidth=3)\n",
    "    axs0.set_xlabel('Iteration', fontsize=16)\n",
    "    axs0.set_ylabel('FOM', fontsize=16)\n",
    "    axs0.set_title('FOM vs Iteration', fontsize=18)\n",
    "\n",
    "    # Plot data on axs2 (Refractive Index Profile)\n",
    "    cmap = 'inferno'\n",
    "    axs2.imshow(n, extent=[x_range[0], x_range[-1], y_range[0], y_range[-1]], cmap=cmap, origin='lower')\n",
    "    axs2.set_xlabel('x (nm)', fontsize=16)\n",
    "    axs2.set_ylabel('y (nm)', fontsize=16)\n",
    "    axs2.set_title('Refractive Index Profile', fontsize=18)\n",
    "\n",
    "    # Plot data on axs1 (Polar plot)\n",
    "    area = 120\n",
    "    axs1.scatter((relative_Phase_delay.cpu().item()), relative_Transmission.cpu().item(), color='red',  s=area, alpha=1, label='RCWA Crystalline Phase', marker=\"d\")\n",
    "    area = 400\n",
    "    axs1.scatter(np.deg2rad(desired_phase_1), desired_amp_1, color='green', s=area, alpha=1, label='Desired Crystalline Phase', marker=\"d\")\n",
    "\n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    os.makedirs('images', exist_ok=True)\n",
    "    output_path = os.path.join('images', output_file)\n",
    "    plt.savefig(output_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7d85395",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:45:55.004099Z",
     "start_time": "2025-05-09T01:45:54.991932Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def plot_real_part_effective_permittivity_and_FOM_online(FOM, iteration,Lx,Ly, ER_t, output_file,\n",
    "                                                  outputs):\n",
    "    index = 0  # Specify the index of the Lc value you want to visualize\n",
    "    real_part = ER_t[0, 0, 0, 0, :, :].real.cpu().detach().numpy()\n",
    "    imag_part = ER_t[0, 0, 0, 1, :, :].real.cpu().detach().numpy()\n",
    "    n = 0.5 * np.sqrt(np.sqrt(imag_part**2 + real_part**2) + real_part)\n",
    "    # Define subplot positions\n",
    "#     pos0 = [0.05, 0.1, 0.28, 0.8]\n",
    "#     pos1 = [0.37, 0.1, 0.28, 0.8]\n",
    "#     pos2 = [0.69, 0.1, 0.28, 0.8]\n",
    "    # Get the dimensions of the real_part array\n",
    "    height, width = real_part.shape\n",
    "\n",
    "    # Calculate the coordinate range\n",
    "    x_range = np.linspace(-width/2, width/2, width)\n",
    "    y_range = np.linspace(-height/2, height/2, height)\n",
    "    x_range = np.multiply(x_range, Lx/width) * 1e9\n",
    "    y_range = np.multiply(y_range, Ly/height) * 1e9\n",
    "    x_range_order = int((outputs[\"T\"][0,0,0,0].shape)[0]/2)\n",
    "    y_range_order = int((outputs[\"T\"][0,0,0,0].shape)[0]/2)\n",
    "    x_range_order_x = np.linspace(-x_range_order, x_range_order,(outputs[\"T\"][0,0,0,0].shape)[0] )\n",
    "    # Create the figure\n",
    "#     fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Create subplots with the defined positions\n",
    "#     axs0 = fig.add_axes(pos0)\n",
    "#     axs1 = fig.add_axes(pos1, projection='polar')\n",
    "#     axs2 = fig.add_axes(pos2)\n",
    "\n",
    "    # Plot data on axs0 (FOM vs Iteration)\n",
    "    axs0.plot(iteration, FOM, color='red', linewidth=3)\n",
    "    axs0.set_xlabel('Iteration', fontsize=14)\n",
    "    axs0.set_ylabel('FOM', fontsize=14)\n",
    "    axs0.set_title('FOM vs Iteration', fontsize=16)\n",
    "\n",
    "    # Plot data on axs2 (Refractive Index Profile)\n",
    "    cmap = 'inferno'\n",
    "    im =  axs2.imshow(n, extent=[x_range[0], x_range[-1], y_range[0], y_range[-1]], cmap=cmap, origin='lower')\n",
    "    axs2.set_xlabel('x (nm)', fontsize=14)\n",
    "    axs2.set_ylabel('y (nm)', fontsize=14)\n",
    "    axs2.set_title('Refractive Index Profile', fontsize=16)\n",
    "    \n",
    "    # Add a colorbar to the heatmap\n",
    "#     plt.colorbar(heatmap, ax=axs2)\n",
    "#     axs1.imshow(outputs[\"T\"][0,0,0].cpu().detach(), extent=[-x_range_order, x_range_order, -y_range_order, y_range_order], cmap=cmap, origin='lower')\n",
    "    axs1.clear() \n",
    "    axs1.plot(x_range_order_x,(outputs[\"T\"][0,0,0,x_range_order,:].cpu()).detach(),color='blue', linewidth=3.5, label='Transmission')\n",
    "    axs1.plot(x_range_order_x,(outputs[\"R\"][0,0,0,x_range_order,:].cpu()).detach(),color='green', linewidth=3.5,  label='Reflection')\n",
    "\n",
    "    # Plotting red dots\n",
    "    axs1.scatter(x_range_order_x,(outputs[\"T\"][0,0,0,x_range_order,:].cpu()).detach(), color='red')  # Adjust color as needed\n",
    "    axs1.scatter(x_range_order_x,(outputs[\"R\"][0,0,0,x_range_order,:].cpu()).detach(), color='black')  # Adjust color as needed\n",
    "    axs1.legend()\n",
    "\n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    os.makedirs('images_opt', exist_ok=True)\n",
    "    output_path = os.path.join('images_opt', output_file)\n",
    "    plt.savefig(output_path)\n",
    "    plt.show()\n",
    "    plt.pause(0.01)  # Pause to allow the plot to be updated\n",
    "    return im\n",
    "# plot_real_part_effective_permittivity_and_FOM_online(loss_mat, step, Lx,Ly, ER_t,str(iteration)+'.png',\n",
    "#                                                          outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae16f420",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:45:55.417010Z",
     "start_time": "2025-05-09T01:45:55.405943Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "#############################################\n",
    "var_shape = (1)\n",
    "desired_phase_1 = 180\n",
    "desired_amp_1 = 1\n",
    "desired_phase_2 = 45\n",
    "desired_amp_2 = 1\n",
    "#############################################\n",
    "desired_phase_1 = desired_phase_1 * np.ones(shape = var_shape)\n",
    "desired_phase_1 = torch.tensor(desired_phase_1, dtype=torch.float32,requires_grad=True)\n",
    "#############################################\n",
    "desired_phase_2 = desired_phase_2 * np.ones(shape = var_shape)\n",
    "desired_phase_2 = torch.tensor(desired_phase_2, dtype=torch.float32,requires_grad=True)\n",
    "# plot_real_part_effective_permittivity_and_FOM(0, 0, Lx, ER_t, 'refIndex.pdf',relative_Transmission,relative_Phase_delay\n",
    "#                                               ,desired_phase_1_num,desired_phase_2_num,\n",
    "#                                                  desired_amp_1,desired_amp_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afdd401b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:45:56.200325Z",
     "start_time": "2025-05-09T01:45:56.191405Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_func_ref(eps_r_ref):\n",
    "  global params\n",
    "    # Generate permittivity and permeability distributions.\n",
    "  ER_t, UR_t = solver.generate_arbitrary_epsilon(eps_r_ref, params)\n",
    "  PQ_zero = torch.tensor(params[\"PQ\"]).prod() // 2\n",
    "  ## Simulation\n",
    "  outputs = solver.simulate(ER_t, UR_t, params)\n",
    "  tx = outputs[\"tx\"][:, :, :, PQ_zero, 0] # Get the zero order field by PQ_zero\n",
    "  ty = outputs[\"ty\"][:, :, :, PQ_zero, 0] \n",
    "  field = torch.unsqueeze(torch.transpose(torch.stack((tx, ty)), 0, 1), 0)\n",
    "#   plot_real_part_effective_permittivity(params[\"Lx\"],ER_t, 'refIndex.pdf')\n",
    "  transmitted_field = torch.squeeze(field)\n",
    "  transmitted_field = transmitted_field[0]\n",
    "  return transmitted_field.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dad796a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:45:56.778404Z",
     "start_time": "2025-05-09T01:45:56.767309Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_func_spec(ER_t, UR_t,params,desired_phase_1,desired_phase_2,transmitted_field_ref):\n",
    "  # Generate permittivity and permeability distributions.\n",
    "  PQ_zero = torch.tensor(params[\"PQ\"]).prod() // 2\n",
    "  ## Simulation\n",
    "  outputs = solver.simulate(ER_t, UR_t, params)\n",
    "  tx = outputs[\"tx\"][:, :, :, PQ_zero, 0] # Get the zero order field by PQ_zero\n",
    "  ty = outputs[\"ty\"][:, :, :, PQ_zero, 0] \n",
    "  field = torch.unsqueeze(torch.transpose(torch.stack((tx, ty)), 0, 1), 0)\n",
    "#   plot_real_part_effective_permittivity(params[\"Lx\"],ER_t, 'refIndex.pdf')\n",
    "  transmitted_field = torch.squeeze(field)\n",
    "  transmitted_field = transmitted_field\n",
    "  relative_Transmission = torch.abs((transmitted_field)/ np.abs(transmitted_field_ref))**2\n",
    "  relative_Phase_delay = torch.angle(torch.exp(1j* (torch.angle(transmitted_field))-np.angle(transmitted_field_ref)))\n",
    "#   transmitted_field = transmitted_field-transmitted_field_ref\n",
    "  desired_phase_1 = torch.deg2rad(desired_phase_1).to(\"cuda\")\n",
    "  desired_phase_2 =  torch.deg2rad(desired_phase_2).to(\"cuda\")\n",
    "  arg_1 = -1j*(torch.log(transmitted_field/torch.sqrt(torch.multiply(transmitted_field,torch.conj(transmitted_field)))))\n",
    "  arg_1 = arg_1.to(\"cuda\")\n",
    "  dif = (torch.cos(desired_phase_1)-torch.cos(arg_1))+(torch.sin(desired_phase_1)-torch.sin(arg_1))\n",
    "#   print(arg_1-relative_Phase_delay)\n",
    "  FOM =(1-relative_Transmission)*(dif)\n",
    "  return FOM,relative_Transmission,relative_Phase_delay,ER_t, UR_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cee0cd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:45:57.307714Z",
     "start_time": "2025-05-09T01:45:57.296444Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def gaussian_kernel(size: int, std: float):\n",
    "    \"\"\"Generate a 2D Gaussian kernel.\"\"\"\n",
    "    coords = torch.linspace(-size, size, 2*size+1)\n",
    "    g = torch.exp(-(coords**2) / (2*std**2))\n",
    "    g_norm = g / g.sum()\n",
    "    g2d = g_norm[:, None] * g_norm[None, :]\n",
    "    return g2d\n",
    "def generate_eps_r(Nx, Ny, eps_min, eps_max, asymmetry_y=False, asymmetry_x=False):\n",
    "    mean = abs(eps_min + eps_max) / 2  # Set the mean of the normal distribution\n",
    "    std = abs(eps_max - eps_min) / 1  # Set the standard deviation of the normal distribution\n",
    "    \n",
    "    # Generate eps_r based on the given conditions\n",
    "    if asymmetry_y and asymmetry_x:\n",
    "        square_size = Nx // 2\n",
    "        square_eps_r = torch.normal(mean, std, size=(square_size, square_size))\n",
    "        flipped_eps_r = torch.flip(square_eps_r, dims=[0, 1])\n",
    "        eps_r = torch.cat((torch.cat((flipped_eps_r, flipped_eps_r.flip(1)), dim=1),\n",
    "                   torch.cat((flipped_eps_r.flip(0), flipped_eps_r.flip(0).flip(1)), dim=1)), dim=0)\n",
    "\n",
    "    elif asymmetry_y:\n",
    "        square_size = Ny // 2\n",
    "        square_eps_r = torch.normal(mean, std, size=(square_size, Ny))\n",
    "        eps_r = torch.cat((square_eps_r, square_eps_r.flip(0)), dim=0)\n",
    "\n",
    "    elif asymmetry_x:\n",
    "        square_size = Nx // 2\n",
    "        square_eps_r = torch.normal(mean, std, size=(Nx, square_size))\n",
    "        eps_r = torch.cat((square_eps_r, square_eps_r.flip(1)), dim=1)\n",
    "        \n",
    "    else:\n",
    "        eps_r = torch.normal(mean, std, size=(Nx, Ny))\n",
    "\n",
    "    # Applying convolution to smooth the eps_r tensor\n",
    "    kernel = gaussian_kernel(3, 2)  # Define the Gaussian kernel\n",
    "    kernel = kernel[None, None, :, :]  # Add extra dimensions to the kernel for batch and channel\n",
    "    eps_r = eps_r[None, None, :, :]    # Add batch and channel dimensions to eps_r\n",
    "    eps_r = F.conv2d(eps_r, kernel, padding=3)\n",
    "    eps_r = eps_r.squeeze()  # Remove batch and channel dimensions\n",
    "\n",
    "    eps_r.requires_grad = True\n",
    "\n",
    "    return eps_r\n",
    "# Test the function\n",
    "# eps_r = generate_eps_r(100, 100, 1, 5, asymmetry_y=True, asymmetry_x=True)\n",
    "# # Plotting the tensor\n",
    "# plt.imshow(eps_r.cpu().detach().numpy(), cmap='viridis')\n",
    "# plt.colorbar()\n",
    "# plt.title(\"Generated eps_r\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5dbe239",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:00.116903Z",
     "start_time": "2025-05-09T01:45:57.887297Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jchang427\\Downloads\\ToJiu\\solver.py:1316: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  k0 = torch.tensor(2 * np.pi / params['lam0'], dtype = torch.cfloat).clone().detach().to(torch.cfloat).to(\"cuda\")\n",
      "c:\\Users\\jchang427\\Downloads\\ToJiu\\solver.py:1317: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kinc_x0 = torch.tensor(n1 * torch.sin(params['theta']) * torch.cos(params['phi'])\n",
      "c:\\Users\\jchang427\\Downloads\\ToJiu\\solver.py:1319: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kinc_y0 = torch.tensor(n1 * torch.sin(params['theta']) * torch.sin(params['phi'])\n",
      "c:\\Users\\jchang427\\Downloads\\ToJiu\\solver.py:1321: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kinc_z0 = torch.tensor(n1 * torch.cos(params['theta']), dtype = torch.cfloat).to(\"cuda\")\n",
      "c:\\Users\\jchang427\\Downloads\\ToJiu\\solver.py:1613: UserWarning: Using torch.cross without specifying the dim arg is deprecated.\n",
      "Please either pass the dim explicitly or simply use torch.linalg.cross.\n",
      "The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\Cross.cpp:66.)\n",
      "  atm_cross = torch.cross(kinc_pol, ate)\n"
     ]
    }
   ],
   "source": [
    "# Initialize global `params` dictionary storing optimization and simulation settings.\n",
    "params = solver.initialize_params(wavelengths = [1550.0],\n",
    "                                  thetas = [0.0],\n",
    "                                  erd =12.64, # Negative imaginary part convention for loss\n",
    "                                          ers = 1.69 ,\n",
    "                                  PQ = [7, 7],\n",
    "                                  L = [ 400.0, 2500.0],\n",
    "                                  Lx = 1260.0,\n",
    "                                  Ly = 1260.0,\n",
    "                                  Nx = 128)\n",
    "N_x = params['Nx']\n",
    "N_y = params['Ny']\n",
    "eps_min = params['eps_min']\n",
    "eps_max = params['eps_max']\n",
    "asymmetry_y = False\n",
    "asymmetry_x = False\n",
    "eps_r = generate_eps_r(N_x,N_y, eps_min, eps_max, asymmetry_y, asymmetry_x)\n",
    "eps_r_ref = generate_eps_r(N_x,N_y, eps_min, eps_min, asymmetry_y, asymmetry_x)\n",
    "transmitted_field_ref = loss_func_ref(eps_r_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7ad6ea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:00.126176Z",
     "start_time": "2025-05-09T01:46:00.118922Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_func_binary_ER_t(binary_ER_t,UR_t,params):\n",
    "  outputs = solver.simulate(ER_t, UR_t, params)\n",
    "  # Maximize the reflectance.\n",
    "  ref_lambda1 = (outputs['REF'][0, 0, 0])\n",
    "  return (1- ref_lambda1),ER_t,UR_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2710b16e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:00.136709Z",
     "start_time": "2025-05-09T01:46:00.126176Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def apply_threshold(ER_t, threshold, eps_min, eps_max):\n",
    "    # Split the complex tensor into real and imaginary parts\n",
    "    ER_real = ER_t.real.to(\"cpu\")\n",
    "    ER_imag = ER_t.imag.to(\"cpu\")\n",
    "\n",
    "    # Apply the thresholding condition\n",
    "    binary_ER_real = torch.where(ER_real < threshold, eps_min, eps_max)\n",
    "    binary_ER_imag = torch.where(ER_imag < threshold, eps_min, eps_max)\n",
    "\n",
    "    # Combine the thresholded real and imaginary parts\n",
    "    binary_ER_t = binary_ER_real + 1j * binary_ER_imag\n",
    "\n",
    "    return binary_ER_t\n",
    "# threshold = 5.5  # Set the threshold value\n",
    "# eps_min = 1.0   # Minimum value for thresholding\n",
    "# eps_max = 10.75  # Maximum value for thresholding\n",
    "# binary_ER_t = apply_threshold(ER_t, threshold, eps_min, eps_max)\n",
    "# plot_real_part_effective_permittivity(Lx,binary_ER_t, 'refIndex.png')\n",
    "# plotter_iteration(loss, step, 'Transmission', 'images/Reflection.pdf', color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73ee772f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:00.156597Z",
     "start_time": "2025-05-09T01:46:00.143427Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\jchang427\\AppData\\Local\\Temp\\ipykernel_10052\\3610730758.py:7: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  wavelengths, n_values, k_values = read_material_file('material\\AM_SB2_S3.txt')\n"
     ]
    }
   ],
   "source": [
    "def Spectrum(Lx,delta,start_wavelength,end_wavelength):\n",
    "    Reflection = []\n",
    "    wavelength_mat = []\n",
    "    epsilon_mat = []\n",
    "    thetas_mat = []\n",
    "    stepnum = int((end_wavelength-start_wavelength)/delta)+1\n",
    "    wavelengths, n_values, k_values = read_material_file('material\\AM_SB2_S3.txt')\n",
    "    params = solver.initialize_params(wavelengths = [1550])  \n",
    "    for i in range (0,stepnum):\n",
    "        wavelength = start_wavelength+i*delta\n",
    "        n, k, epsilon = interpolate_material(wavelengths, n_values, k_values, wavelength*1e-3)\n",
    "        wavelength_mat.append(wavelength)\n",
    "        epsilon_mat.append(np.conj(epsilon))\n",
    "        thetas_mat.append(0.0)\n",
    "    for i in range (0,stepnum):\n",
    "        params = solver.initialize_params(wavelengths = [wavelength_mat[i]], thetas=[0.0],\n",
    "                                          erd=[epsilon_mat[i]],ers=2.25, PQ=[11, 11],\n",
    "                                  L=[400, 2500.0], Lx=950.0, Ly=950.0, Nx=128)\n",
    "        Transmission = loss_func_binary_ER_t(binary_ER_t,UR_t,params)\n",
    "        Reflection.append(1-Transmission[0].item())\n",
    "        if i%5 == 0:\n",
    "            print(\"simulating wavelength:\",wavelength_mat[i])\n",
    "#             print(\"simulating epsilon:\",epsilon_mat[i])\n",
    "\n",
    "    Reflection = np.array(Reflection)\n",
    "    wavelength_mat = np.array(wavelength_mat)\n",
    "#     del var_duty\n",
    "#     torch.cuda.empty_cache()\n",
    "    return Reflection,wavelength_mat,ER_t\n",
    "############################################################################\n",
    "#######Initialize grating duty cycle variable.\n",
    "# delta = 1*(5)+1\n",
    "# Lx = 128\n",
    "# start_wavelength = 1520# 375\n",
    "# end_wavelength = 1530# 750\n",
    "# Reflection,wavelength_mat,ER_t = Spectrum(Lx,delta,start_wavelength,end_wavelength)\n",
    "# plot_combined(Lx, ER_t.cpu().detach().numpy(), Reflection, wavelength_mat, 'combined_plot.png')\n",
    "\n",
    "# plot_real_part_effective_permittivity(Lx,ER_t, 'refIndex.pdf')\n",
    "# plotter(Reflection, wavelength_mat, 'Reflection', 'images/Reflection.png', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bce83245",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:00.855856Z",
     "start_time": "2025-05-09T01:46:00.847492Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def density_filter_2d(pattern_in, radius):\n",
    "    # If the radius is less than 1 pixel, no filter can be applied\n",
    "    if radius < 1:\n",
    "        pattern_out = pattern_in\n",
    "    else:\n",
    "        # Define grid\n",
    "        x = torch.arange(-int(torch.ceil(torch.tensor(float(radius))).item()),\n",
    "                         int(torch.ceil(torch.tensor(float(radius))).item()) + 1,\n",
    "                         device=pattern_in.device)\n",
    "        X1, X2 = torch.meshgrid(x, x)\n",
    "        # Compute weights\n",
    "        weights = radius - torch.sqrt(X1**2 + X2**2)\n",
    "        weights[weights < 0] = 0\n",
    "        b = torch.sum(weights)\n",
    "        # Apply filter\n",
    "        pattern_out = F.conv2d(pattern_in.unsqueeze(0).unsqueeze(0).to(pattern_in.device),\n",
    "                               weights.unsqueeze(0).unsqueeze(0).to(pattern_in.device) / b,\n",
    "                               padding=int(radius))\n",
    "        pattern_out = pattern_out.squeeze(0).squeeze(0)\n",
    "    return pattern_out\n",
    "# Define blur kernel\n",
    "# blur_radius = 7\n",
    "# threshold = 0.5\n",
    "# normalized_eps_r = (eps_r - eps_min) / eps_max\n",
    "# density_filter_2d(normalized_eps_r, blur_radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eec76fe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:01.480028Z",
     "start_time": "2025-05-09T01:46:01.471456Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def adjust_eps_r(eps_r, threshold=0.5, increment=0.01):\n",
    "    \"\"\"\n",
    "    Adjusts elements of a PyTorch tensor eps_r based on a threshold.\n",
    "\n",
    "    Args:\n",
    "        eps_r (torch.Tensor): Input PyTorch tensor.\n",
    "        threshold (float): Threshold value.\n",
    "        increment (float): Value to add or subtract from elements based on the threshold.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Adjusted tensor.\n",
    "    \"\"\"\n",
    "    # Create masks for elements greater and smaller than the threshold\n",
    "    above_threshold = eps_r > threshold\n",
    "    below_threshold = eps_r < threshold\n",
    "    # Apply adjustments\n",
    "    adjusted_eps_r = eps_r.clone()  # Create a copy to avoid modifying the original tensor\n",
    "    adjusted_eps_r[above_threshold] += increment\n",
    "    adjusted_eps_r[below_threshold] -= increment\n",
    "    return adjusted_eps_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54b39d7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:01.915208Z",
     "start_time": "2025-05-09T01:46:01.904205Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def generate_bvector(max_iterations, bin_parm):\n",
    "    # Extract parameters\n",
    "    b_min = bin_parm['Min']# Minimum value of B that is used after it is initialized.\n",
    "    b_max = bin_parm['Max']# Maximum value of B\n",
    "    b_start = bin_parm['IterationStart'] #Iteration at which B is allowed to be nonzero.\n",
    "    b_hold = bin_parm['IterationHold'] #Number of iterations during which B is kept constant before increasing (after it is initialized)\n",
    "    b_mid = b_max / 20\n",
    "    b_vector = torch.zeros(max_iterations)\n",
    "    bmult1 = (b_mid / b_min) ** (1 / torch.floor(torch.tensor((round(max_iterations / 2) - b_start) / b_hold)))\n",
    "    bmult2 = (b_max / b_mid) ** (1 / torch.floor(torch.tensor((round(max_iterations / 2)) / b_hold)))\n",
    "    # The binarization speed is a piecewise function\n",
    "    b_vector[b_start:round(max_iterations / 2)] = b_min * bmult1 ** (torch.floor((torch.arange(round(max_iterations / 2) - b_start) + 1) / b_hold))\n",
    "    b_vector[round(max_iterations / 2):] = b_mid * bmult2 ** (torch.floor((torch.arange(max_iterations - round(max_iterations / 2)) + 1) / b_hold))\n",
    "    return b_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2064c7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:02.334259Z",
     "start_time": "2025-05-09T01:46:02.319118Z"
    },
    "code_folding": [
     0,
     20,
     29
    ]
   },
   "outputs": [],
   "source": [
    "def custom_gaussian_blur(image, kernel_size, sigma):\n",
    "    \"\"\"\n",
    "    Custom Gaussian blur implementation using 2D convolution.\n",
    "    \"\"\"\n",
    "    # Create a 1D Gaussian kernel\n",
    "    x = torch.linspace(-kernel_size // 2 + 1, kernel_size // 2, kernel_size)\n",
    "    gauss_1d = torch.exp(-0.5 * (x / sigma).pow(2))\n",
    "    gauss_1d /= gauss_1d.sum()\n",
    "    \n",
    "    # Create a 2D Gaussian kernel\n",
    "    gauss_2d = gauss_1d[:, None] * gauss_1d[None, :]\n",
    "    gauss_2d = gauss_2d / gauss_2d.sum()\n",
    "    \n",
    "    # Expand dimensions to match the input tensor\n",
    "    gauss_2d = gauss_2d[None, None, :, :]\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    blurred_img = F.conv2d(image[None, None, :, :], gauss_2d, padding=kernel_size // 2)[0][0]\n",
    "    \n",
    "    return blurred_img\n",
    "def enforce_symmetry(pattern, sym_x, sym_y):\n",
    "    \"\"\"\n",
    "    Enforce symmetry on the pattern.\n",
    "    \"\"\"\n",
    "    if sym_x:\n",
    "        pattern = (pattern + pattern.flip(-2)) / 2\n",
    "    if sym_y:\n",
    "        pattern = (pattern + pattern.flip(-1)) / 2\n",
    "    return pattern\n",
    "def random_start(n_x, n_y, period, rand_parm, sym_x, sym_y):\n",
    "    \"\"\"\n",
    "    Generate a random starting pattern.\n",
    "    \"\"\"\n",
    "    pitch = rand_parm['Pitch']\n",
    "    rand_average = rand_parm['Average']\n",
    "    rand_sigma = rand_parm['Sigma']\n",
    "    n_cells_x = math.ceil(2 * period[0] / pitch)\n",
    "    n_cells_y = math.ceil(2 * period[1] / pitch)\n",
    "    grid_size = period[0] / n_x\n",
    "\n",
    "    # Normally distributed index of refractions\n",
    "    random_indices = rand_average * torch.ones(n_cells_x, n_cells_y) + rand_sigma * torch.randn(n_cells_x, n_cells_y)\n",
    "    random_indices = enforce_symmetry(random_indices, sym_x, sym_y)\n",
    "\n",
    "    # Upsample the random pattern\n",
    "    random_pattern = F.interpolate(random_indices[None, None, :, :], size=(n_x, n_y), mode='bilinear')[0][0]\n",
    "\n",
    "    # Gaussian blur the pattern\n",
    "    blur_size = int(1.0 * pitch / grid_size)\n",
    "    random_pattern = custom_gaussian_blur(random_pattern, blur_size, 0.3)\n",
    "\n",
    "    # Ensure the pattern is proper\n",
    "    random_pattern = enforce_symmetry(random_pattern, sym_x, sym_y)\n",
    "    random_pattern = torch.clamp(random_pattern, 0, 1)\n",
    "    random_pattern.requires_grad = True\n",
    "\n",
    "    return random_pattern\n",
    "# # Example\n",
    "# rand_parm = {\n",
    "#     'Pitch': 0.05,\n",
    "#     'Average': 0.5,\n",
    "#     'Sigma': 0.4\n",
    "# }\n",
    "# pattern = random_start(512, 512, (1, 1), rand_parm, True, True)\n",
    "# print(pattern)\n",
    "# plt.imshow(pattern.detach().numpy())\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43ebd452",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:02.808806Z",
     "start_time": "2025-05-09T01:46:02.800335Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def thresh_filter(pattern_in, bin, midpoint):\n",
    "    \"\"\"\n",
    "    Apply a threshold filter to the input pattern.\n",
    "    \"\"\"\n",
    "    bin = torch.tensor(bin)\n",
    "    midpoint = torch.tensor(midpoint)\n",
    "    \n",
    "    if bin != 0:\n",
    "        patt_norm_low = 1 - pattern_in / midpoint\n",
    "        pattern_low = midpoint * (torch.exp(-bin * patt_norm_low) - patt_norm_low * torch.exp(-bin))\n",
    "        \n",
    "        patt_norm_high = (pattern_in - midpoint) / (1 - midpoint)\n",
    "        pattern_high = midpoint + (1 - midpoint) * (1 - torch.exp(-bin * patt_norm_high) + patt_norm_high * torch.exp(-bin))\n",
    "    else:\n",
    "        pattern_low = pattern_in / (2 * midpoint)\n",
    "        pattern_high = (pattern_in - 1) / (2 - 2 * midpoint) + 1\n",
    "    \n",
    "    pattern_out = pattern_low * (pattern_in <= midpoint) + pattern_high * (pattern_in > midpoint)\n",
    "\n",
    "    return pattern_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "930c5405",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:03.216943Z",
     "start_time": "2025-05-09T01:46:03.196745Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def generate_thresh_vectors(opt_parm):\n",
    "    \"\"\"\n",
    "    Generate thresholding parameters for robustness.\n",
    "\n",
    "    Args:\n",
    "    - opt_parm (dict): Dictionary containing optimization parameters.\n",
    "\n",
    "    Returns:\n",
    "    - threshold_vectors (Tensor): Tensor containing thresholding parameters.\n",
    "    - n_robustness (int): Number of robustness parameters.\n",
    "    \"\"\"\n",
    "    max_iterations = opt_parm['Optimization']['Iterations']\n",
    "    start = torch.tensor(opt_parm['Optimization']['Robustness']['StartDeviation'])\n",
    "    end = torch.tensor(opt_parm['Optimization']['Robustness']['EndDeviation'])\n",
    "    ramp = opt_parm['Optimization']['Robustness']['Ramp']\n",
    "    n_robustness = len(start)\n",
    "\n",
    "    if n_robustness != len(end):\n",
    "        raise ValueError('Robustness vectors are not the same length!')\n",
    "\n",
    "    deviation_vectors = torch.zeros((n_robustness, max_iterations))\n",
    "\n",
    "    for ii in range(n_robustness):\n",
    "        deviation_vectors[ii, :ramp] = torch.linspace(start[ii], end[ii], ramp)\n",
    "        deviation_vectors[ii, ramp:] = end[ii]\n",
    "\n",
    "    blur_radius = opt_parm['Optimization']['Filter']['BlurRadius']\n",
    "    threshold_vectors = 0.5 * (1 - torch.from_numpy(erf(deviation_vectors.numpy() / blur_radius)))\n",
    "\n",
    "    return threshold_vectors, n_robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79aaa995",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:03.616385Z",
     "start_time": "2025-05-09T01:46:03.595943Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def gauss_filter_2d(pattern_in, blure_radius):\n",
    "    # Create a Gaussian kernel using PyTorch's inbuilt functions\n",
    "    # Note: This creates a 1D Gaussian kernel; to get the 2D version, we'll take an outer product\n",
    "    gauss_1d = torch.exp(-torch.linspace(-2*blure_radius, 2*blure_radius, 4*blure_radius+1)**2 / (2*blure_radius**2)).to(\"cuda\")\n",
    "    gauss_2d = torch.outer(gauss_1d, gauss_1d).to(\"cuda\")\n",
    "    \n",
    "    # Normalize the kernel to make sure the weights sum to 1\n",
    "    gauss_2d /= gauss_2d.sum()\n",
    "    \n",
    "    # Adjust pattern_in to have an extra dimension for convolution to work\n",
    "    pattern_in = pattern_in[None, None, :, :]\n",
    "    \n",
    "    # Apply the Gaussian filter using PyTorch's functional API\n",
    "    # The padding is done to handle boundaries (circular padding is simulated by periodic padding)\n",
    "    filtered_pattern = F.conv2d(pattern_in, gauss_2d[None, None, :, :], padding=blure_radius)\n",
    "    filtered_pattern = filtered_pattern.squeeze()\n",
    "\n",
    "    # Squeeze out the extra dimensions\n",
    "    return filtered_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fd99441",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:04.066874Z",
     "start_time": "2025-05-09T01:46:04.046699Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def pad_to_size_with_ones(tensor, target_size):\n",
    "    \"\"\"\n",
    "    Pads a 2D tensor to the given target size using ones.\n",
    "    \"\"\"\n",
    "    # Compute padding amounts\n",
    "    pad_diff = torch.tensor(target_size) - torch.tensor(tensor.size())\n",
    "    pad_left = pad_diff // 2\n",
    "    pad_right = pad_diff - pad_left\n",
    "    \n",
    "    # Apply padding\n",
    "    padded_tensor = F.pad(tensor, (pad_left[1].item(), pad_right[1].item(), pad_left[0].item(), pad_right[0].item()), value=1)\n",
    "    \n",
    "    return padded_tensor\n",
    "\n",
    "# Example usage:\n",
    "# eps_r = pad_to_size_with_ones(eps_r, [128, 128])\n",
    "# plt.imshow(eps_r.cpu().detach().numpy(), cmap='viridis')\n",
    "# plt.colorbar()\n",
    "# eps_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d56cd56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:04.500181Z",
     "start_time": "2025-05-09T01:46:04.494484Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def pad_to_size_with_zeros(tensor, target_size):\n",
    "    \"\"\"\n",
    "    Pads a 2D tensor to the given target size using ones.\n",
    "    \"\"\"\n",
    "    # Compute padding amounts\n",
    "    pad_diff = torch.tensor(target_size) - torch.tensor(tensor.size())\n",
    "    pad_left = pad_diff // 2\n",
    "    pad_right = pad_diff - pad_left\n",
    "    \n",
    "    # Apply padding\n",
    "    padded_tensor = F.pad(tensor, (pad_left[1].item(), pad_right[1].item(), pad_left[0].item(), pad_right[0].item()), value=0)\n",
    "    \n",
    "    return padded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b500244",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:04.916973Z",
     "start_time": "2025-05-09T01:46:04.906941Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def gauss_grad_2d(gradient_in, pattern_in, bin_val, midpoint, sigma):\n",
    "    \"\"\"\n",
    "    Computes the base pattern gradient from the Gaussian and threshold filtered gradient.\n",
    "    \"\"\"\n",
    "    bin_val = torch.tensor(bin_val)\n",
    "    \n",
    "    # Compute the derivative of the threshold filter\n",
    "    if bin_val != 0:\n",
    "        pattern_low = bin_val * (torch.exp(-bin_val * (1 - pattern_in / midpoint))) + torch.exp(-bin_val)\n",
    "        pattern_high = torch.exp(-bin_val) + bin_val * torch.exp(-bin_val * (pattern_in - midpoint) / (1 - midpoint))\n",
    "    else:\n",
    "        pattern_low = torch.ones_like(pattern_in) / (2 * midpoint)\n",
    "        pattern_high = torch.ones_like(pattern_in) / (2 * (1 - midpoint))\n",
    "    \n",
    "    # Combine the two pieces of the threshold derivative\n",
    "    pattern_low[pattern_in > midpoint] = 0\n",
    "    pattern_high[pattern_in <= midpoint] = 0\n",
    "    pattern_deriv = pattern_low + pattern_high\n",
    "    \n",
    "    # Apply chain rule\n",
    "    gradient = pattern_deriv * gradient_in\n",
    "    \n",
    "    # Chain rule of Gaussian filter is another Gaussian\n",
    "    gradient_out = density_filter_2d(gradient, sigma)\n",
    "    \n",
    "    return gradient_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0cf26371",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:05.233600Z",
     "start_time": "2025-05-09T01:46:05.213411Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def filtered_grad_2d(gradient_in, pattern_in, bin_val, midpoint, radius):\n",
    "    \"\"\"\n",
    "    Compute the gradient from the density and threshold filtered gradient.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert scalars to tensors\n",
    "    bin_tensor = torch.tensor(bin_val, dtype=gradient_in.dtype, device=gradient_in.device)\n",
    "    \n",
    "    # Compute the derivative of the threshold filter\n",
    "    if bin_val != 0:\n",
    "        pattern_low = bin_tensor * (torch.exp(-bin_tensor * (1 - pattern_in / midpoint))) + torch.exp(-bin_tensor)\n",
    "        pattern_high = torch.exp(-bin_tensor) + bin_tensor * torch.exp(-bin_tensor * (pattern_in - midpoint) / (1 - midpoint))\n",
    "    else:\n",
    "        pattern_low = torch.ones_like(pattern_in) / (2 * midpoint)\n",
    "        pattern_high = torch.ones_like(pattern_in) / (2 * (1 - midpoint))\n",
    "    \n",
    "    # Combine the two pieces of the threshold derivative\n",
    "    pattern_low[pattern_in > midpoint] = 0\n",
    "    pattern_high[pattern_in <= midpoint] = 0\n",
    "    pattern_deriv = pattern_low + pattern_high\n",
    "    \n",
    "    # Apply chain rule\n",
    "    gradient = pattern_deriv * gradient_in\n",
    "    \n",
    "    # Chain rule of the DensityFilter is another DensityFilter\n",
    "    gradient_out = density_filter_2d(gradient, radius)\n",
    "    return gradient_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b135c267",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:05.400224Z",
     "start_time": "2025-05-09T01:46:05.386597Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def enforce_symmetry(pattern_in, sym_x, sym_y):\n",
    "    \"\"\"\n",
    "    Enforces required symmetries in the pattern by folding over midline and averaging.\n",
    "    \"\"\"\n",
    "    pattern_out = pattern_in.clone()\n",
    "    \n",
    "    # Enforce X symmetry\n",
    "    if sym_x:\n",
    "        pattern_out = 0.5 * (pattern_out + torch.flip(pattern_out, [0]))\n",
    "    \n",
    "    # Enforce Y symmetry\n",
    "    if sym_y:\n",
    "        pattern_out = 0.5 * (pattern_out + torch.flip(pattern_out, [1]))\n",
    "        \n",
    "    return pattern_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a81fe54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:05.750303Z",
     "start_time": "2025-05-09T01:46:05.740287Z"
    },
    "code_folding": [
     0,
     13
    ]
   },
   "outputs": [],
   "source": [
    "def create_disk_filter(radius):\n",
    "    # Ensure radius is an integer\n",
    "    radius = int(radius)\n",
    "    # Generate the grid\n",
    "    y, x = np.ogrid[-radius: radius+1, -radius: radius+1]\n",
    "    # Create the mask\n",
    "    mask = x**2 + y**2 <= radius**2\n",
    "    # Create the disk using the mask\n",
    "    disk = np.zeros((2*radius+1, 2*radius+1))\n",
    "    disk[mask] = 1\n",
    "    # Normalize and return as a torch tensor\n",
    "    return torch.tensor(disk / disk.sum(), dtype=torch.float32)\n",
    "\n",
    "def blur_geom_post_grad(device_pattern, iteration, opt_parm, grid_scale,max_iterations):    \n",
    "    # Large blur every X iterations\n",
    "    BlurLargeIter = 6\n",
    "    BlurLargeIterstop = 3\n",
    "    BlurRadiusLarge = 6\n",
    "    BlurSmallIter = 3\n",
    "    BlurSmallIterStop = 6\n",
    "    BlurRadiusSmall = 3\n",
    "    if (iteration % BlurLargeIter == 0) and (iteration < max_iterations -BlurLargeIterstop ):\n",
    "        filter_large = create_disk_filter(0.5 * int(BlurRadiusLarge / grid_scale)).cuda()\n",
    "        device_pattern = F.conv2d(device_pattern[None, None, :, :], filter_large[None, None, :, :], padding=filter_large.shape[0] // 2)[0, 0]\n",
    "        device_pattern = device_pattern.to(\"cuda\") \n",
    "    # Small blur every Y iterations\n",
    "    elif (iteration % BlurSmallIter== 0) and (iteration < max_iterations - BlurSmallIterStop):\n",
    "        filter_small = (create_disk_filter(BlurRadiusSmall / grid_scale)).to(\"cuda\") \n",
    "        device_pattern = F.conv2d(device_pattern[None, None, :, :], filter_small[None, None, :, :], padding=filter_small.shape[0] // 2)[0, 0]\n",
    "        device_pattern = device_pattern.to(\"cuda\")   \n",
    "    return device_pattern\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad887056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:06.032751Z",
     "start_time": "2025-05-09T01:46:06.012205Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def define_grid(grid, period, wavelength):\n",
    "    \"\"\"\n",
    "    Compute the simulation grid for given geometry.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Number of grid points\n",
    "    n_grid = np.ceil(np.array(grid) * np.array(period) / wavelength).astype(int)\n",
    "    nx, ny = n_grid\n",
    "    \n",
    "    # Device period\n",
    "    px, py = period\n",
    "    \n",
    "    # Compute external grid coordinates\n",
    "    x_bounds = np.linspace(0, px, nx+1)\n",
    "    y_bounds = np.linspace(0, py, ny+1)\n",
    "    \n",
    "    # Compute size of each grid box\n",
    "    dx = x_bounds[1] - x_bounds[0]\n",
    "    dy = y_bounds[1] - y_bounds[0]\n",
    "    \n",
    "    # Compute coordinates of center of each box\n",
    "    x_grid = x_bounds[1:] - 0.5 * dx\n",
    "    y_grid = y_bounds[1:] - 0.5 * dy\n",
    "    \n",
    "    # Compute average grid size\n",
    "    dr = (np.mean([dx, dy]))\n",
    "    \n",
    "    return x_grid, y_grid, dr\n",
    "# grid = [N_x, N_x]\n",
    "# period = [params[\"Lx\"]*1e9, params[\"Ly\"]*1e9]\n",
    "# wavelength = 1550\n",
    "\n",
    "# x_grid, y_grid, dr = define_grid(grid, period, wavelength)\n",
    "# print(x_grid, y_grid, dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5dcb31f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:06.215853Z",
     "start_time": "2025-05-09T01:46:06.207785Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def replace_nan_with_1(average_final_pattern):\n",
    "    \"\"\"\n",
    "    Replace NaN values in a PyTorch tensor with 1.\n",
    "\n",
    "    Args:\n",
    "        average_final_pattern (torch.Tensor): Input PyTorch tensor.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Tensor with NaN values replaced by 1.\n",
    "    \"\"\"\n",
    "    # Create a mask for NaN values\n",
    "    nan_mask = torch.isnan(average_final_pattern)\n",
    "\n",
    "    # Replace NaN values with 1\n",
    "    average_final_pattern[nan_mask] = 0\n",
    "\n",
    "    return average_final_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1862932",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:06.500198Z",
     "start_time": "2025-05-09T01:46:06.493096Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# BlurGridLarge = 20\n",
    "# rand_parm = {\n",
    "#     'Pitch': 0.2,\n",
    "#     'Average': 0.3,\n",
    "#     'Sigma': 0.6\n",
    "# }\n",
    "# pattern = random_start(N_x, N_y, (period_x, period_y), rand_parm, asymmetry_x, asymmetry_y)\n",
    "# pattern = torch.nn.Parameter(pattern.to(\"cuda\"))  # Wrap eps_r with Parameter for optimization\n",
    "\n",
    "# pattern.requires_grad = True\n",
    "# FilteredPattern = density_filter_2d(pattern, BlurGridLarge)\n",
    "# BinaryPattern = thresh_filter(FilteredPattern, b_vector[iteration], 0.5)\n",
    "# filtered_pattern2 = gauss_filter_2d(BinaryPattern, BlurGrid)\n",
    "\n",
    "# plt.imshow(filtered_pattern2.cpu().detach())\n",
    "# plt.show()\n",
    "# print(pattern.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57ad4f49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:06.932974Z",
     "start_time": "2025-05-09T01:46:06.922836Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_func(eps_r):\n",
    "  # Global parameters dictionary.\n",
    "  global params\n",
    "  # Generate permittivity and permeability distributions.\n",
    "  ER_t, UR_t = solver.generate_arbitrary_epsilon(eps_r, params)\n",
    "  PQ_zero = int(params[\"PQ\"][0]/2)\n",
    "  ## Simulation\n",
    "  outputs = solver.simulate(ER_t, UR_t, params)\n",
    "  tx = outputs[\"tx\"][:, :, :, PQ_zero, 0] # Get the zero order field by PQ_zero\n",
    "  ty = outputs[\"ty\"][:, :, :, PQ_zero, 0] \n",
    "  field = torch.unsqueeze(torch.transpose(torch.stack((tx, ty)), 0, 1), 0)\n",
    "#   plot_real_part_effective_permittivity(params[\"Lx\"],ER_t, 'refIndex.pdf')\n",
    "  transmitted_field = torch.squeeze(field)\n",
    "  transmitted_field = transmitted_field[0]\n",
    "  FOM = outputs[\"T\"][0,0,0,PQ_zero,PQ_zero+1]\n",
    "  return 1-FOM,outputs,ER_t, UR_t,outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2ac8b7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:46:08.249482Z",
     "start_time": "2025-05-09T01:46:07.535560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOM tensor(1.00000012, device='cuda:0', grad_fn=<RsubBackward1>)\n"
     ]
    }
   ],
   "source": [
    "N = 1\n",
    "loss = np.zeros(N + 1)\n",
    "loss,outputs,ER_t, UR_t,outputs = loss_func(eps_r)\n",
    "# plt.imshow(outputs[\"T\"][0,0,0].cpu().detach())\n",
    "print(\"FOM\",loss)\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b81f07b3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-09T01:46:13.246Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jchang427\\AppData\\Local\\Temp\\ipykernel_10052\\1410856916.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bin = torch.tensor(bin)\n",
      "c:\\Users\\jchang427\\Downloads\\ToJiu\\solver.py:1316: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  k0 = torch.tensor(2 * np.pi / params['lam0'], dtype = torch.cfloat).clone().detach().to(torch.cfloat).to(\"cuda\")\n",
      "c:\\Users\\jchang427\\Downloads\\ToJiu\\solver.py:1317: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kinc_x0 = torch.tensor(n1 * torch.sin(params['theta']) * torch.cos(params['phi'])\n",
      "c:\\Users\\jchang427\\Downloads\\ToJiu\\solver.py:1319: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kinc_y0 = torch.tensor(n1 * torch.sin(params['theta']) * torch.sin(params['phi'])\n",
      "c:\\Users\\jchang427\\Downloads\\ToJiu\\solver.py:1321: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kinc_z0 = torch.tensor(n1 * torch.cos(params['theta']), dtype = torch.cfloat).to(\"cuda\")\n",
      "C:\\Users\\jchang427\\AppData\\Local\\Temp\\ipykernel_10052\\1375632908.py:56: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1/20, FOM: 0.9386473894119263\n",
      "Iteration: 2/20, FOM: 0.8819448947906494\n",
      "Iteration: 3/20, FOM: 0.8642287850379944\n",
      "Iteration: 4/20, FOM: 0.8309423327445984\n",
      "Iteration: 5/20, FOM: 0.7974236011505127\n",
      "Iteration: 6/20, FOM: 0.672491729259491\n",
      "Iteration: 7/20, FOM: 0.6716753244400024\n",
      "Iteration: 8/20, FOM: 0.8420930504798889\n",
      "Iteration: 9/20, FOM: 0.8643662333488464\n",
      "Iteration: 10/20, FOM: 0.5973448753356934\n",
      "Iteration: 11/20, FOM: 0.7373912334442139\n",
      "Iteration: 12/20, FOM: 0.857552170753479\n",
      "Iteration: 13/20, FOM: 0.9057371616363525\n",
      "Iteration: 14/20, FOM: 0.9000819325447083\n",
      "Iteration: 15/20, FOM: 0.8908295035362244\n",
      "Iteration: 16/20, FOM: 0.8887088894844055\n",
      "Iteration: 17/20, FOM: 0.8865737915039062\n",
      "Iteration: 18/20, FOM: 0.8896503448486328\n",
      "Iteration: 19/20, FOM: 0.8948459029197693\n",
      "Iteration: 20/20, FOM: 0.9023996591567993\n"
     ]
    }
   ],
   "source": [
    "#Main_Loop\n",
    "##################################################################################################\n",
    "# Number of optimization iterations.\n",
    "iteration_max = 20\n",
    "bin_parm = {'Min': 1,'Max': 20.0,'IterationStart': 1,'IterationHold': 3}\n",
    "b_vector = generate_bvector(iteration_max, bin_parm)\n",
    "opt_parm = {'Optimization': {'Iterations': iteration_max,\n",
    "        'Robustness': {'StartDeviation': [-5, 0, 5],# Starting edge deviation values\n",
    "            'EndDeviation': [-5, 0, 5],# Ending edge deviation values\n",
    "            'Ramp':2,#Iterations over which the thresholding parameter changes\n",
    "            'Weights':[.5, 1, .5]},# Gradient weight for each robustness value\n",
    "            'Filter': {'BlurRadius': 3}}}\n",
    "threshold_vectors, n_robustness = generate_thresh_vectors(opt_parm)\n",
    "##################################################################################################\n",
    "##Optimization:\n",
    "var_shape = (1)\n",
    "desired_phase_1_num = 180\n",
    "desired_amp_1 = 1\n",
    "desired_phase_2_num = 270\n",
    "desired_amp_2 = 1\n",
    "##################################################################################################\n",
    "desired_phase_1 = desired_phase_1_num * np.ones(shape = var_shape)\n",
    "desired_phase_1 = torch.tensor(desired_phase_1, dtype=torch.float32,requires_grad=True)\n",
    "desired_phase_2 = desired_phase_2_num* np.ones(shape = var_shape)\n",
    "desired_phase_2 = torch.tensor(desired_phase_2, dtype=torch.float32,requires_grad=True)\n",
    "##################################################################################################\n",
    "plt.ion()\n",
    "wavelength_list = np.arange(1550, 1551, 2)#[500]\n",
    "params = solver.initialize_params(wavelengths =wavelength_list,\n",
    "                                  thetas = [0.0 for i in wavelength_list],\n",
    "                                  phis= [0.0 for i in wavelength_list],\n",
    "                                  pte= [0.0 for i in wavelength_list],#put real small numer to avoid inf\n",
    "                                  ptm= [1.0 for i in wavelength_list],   \n",
    "                                  erd = 17.64-.0j, # Negative imaginary part convention for loss\n",
    "                                  ers = 1.69 ,\n",
    "                                  PQ = [9, 9],\n",
    "                                  L = [ 320.0, 2500.0],\n",
    "                                  Lx = 2750.0,\n",
    "                                  Ly = 1250.0,\n",
    "                                  Nx = 256,\n",
    "                                  eps_max =16.0-.0j )\n",
    "N_x = params[\"Nx\"]\n",
    "N_y = int(np.round(params['Nx'] * params['Ly'] / params['Lx']))\n",
    "eps_min = params['eps_min']\n",
    "eps_max = params['eps_max']\n",
    "asymmetry_x = False\n",
    "asymmetry_y = False\n",
    "grid = [N_x, N_x]\n",
    "period = [params[\"Lx\"]*1e9, params[\"Ly\"]*1e9]\n",
    "wavelength = wavelength_list[0]\n",
    "x_grid, y_grid, dr = define_grid(grid, period, wavelength)\n",
    "# Example\n",
    "BlurGridLarge = 5\n",
    "rand_parm = {\n",
    "    'Pitch': 0.14,\n",
    "    'Average': 0.5,\n",
    "    'Sigma': 0.95\n",
    "}\n",
    "period_x = 1\n",
    "period_y = 1\n",
    "\n",
    "pattern = random_start(N_x, N_y, (period_x, period_y), rand_parm, asymmetry_x, asymmetry_y)\n",
    "pattern = torch.nn.Parameter(pattern.to(\"cuda\"))  # Wrap eps_r with Parameter for optimization\n",
    "pattern.requires_grad = True\n",
    "Gradient = torch.zeros_like(pattern)\n",
    "Gradient = torch.nn.Parameter(Gradient.to(\"cuda\"))  # Wrap eps_r with Parameter for optimization\n",
    "Gradient.requires_grad = True\n",
    "average_final_pattern = pattern.clone()\n",
    "average_final_pattern = torch.nn.Parameter(average_final_pattern.to(\"cuda\"))  # Wrap eps_r with Parameter for optimization\n",
    "average_final_pattern.requires_grad = True\n",
    "# plt.imshow(pattern.cpu().detach())\n",
    "# plt.show()\n",
    "BlurGrid = 2;\n",
    "##################################################################################################\n",
    "eps_r = generate_eps_r(N_x,N_y, eps_min, eps_max, asymmetry_x, asymmetry_y)\n",
    "eps_r = torch.nn.Parameter(eps_r.to(\"cuda\"))  # Wrap eps_r with Parameter for optimization\n",
    "Lx = params['Lx']\n",
    "Ly = params['Ly']\n",
    "eps_r_ref = generate_eps_r(N_x,N_y, eps_min, eps_min, asymmetry_x, asymmetry_y)\n",
    "# Define an optimizer and data to be stored.\n",
    "optimizer = optim.Adam([eps_r], lr=5e-2)\n",
    "StepSize = 1#  Initial gradient step size\n",
    "StepDecline = 0.99 # Multiplying factor that decreases step size each iteration\n",
    "loss = np.zeros(N)\n",
    "step = []\n",
    "loss_mat = []\n",
    "#####################################################\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "pos0 = [0.06, 0.1, 0.28, 0.8]\n",
    "pos1 = [0.38, 0.1, 0.28, 0.8]\n",
    "pos2 = [0.715, 0.1, 0.28, 0.8]\n",
    "axs0 = fig.add_axes(pos0)\n",
    "axs1 = fig.add_axes(pos1)\n",
    "axs2 = fig.add_axes(pos2)\n",
    "######################################################\n",
    "# Optimize\n",
    "final_pattern_mat = []\n",
    "print('Optimizing...')\n",
    "for iteration in range(iteration_max):\n",
    "    optimizer.zero_grad()\n",
    "    #First filter to enforce binarization\n",
    "    FilteredPattern = density_filter_2d(pattern, BlurGridLarge)\n",
    "    BinaryPattern = thresh_filter(FilteredPattern, b_vector[iteration], 0.5)#\n",
    "#     accumulator = torch.zeros_like(BinaryPattern)\n",
    "# #     # Begin robustness loop\n",
    "#     for robust_iter in range(n_robustness):\n",
    "#         # Second filter to model physical edge deviations\n",
    "#         filtered_pattern2 = gauss_filter_2d(BinaryPattern, BlurGrid)\n",
    "#         final_pattern = thresh_filter(filtered_pattern2, b_vector[iteration], threshold_vectors[robust_iter, iteration])\n",
    "#         final_pattern = pad_to_size_with_zeros(final_pattern, [BinaryPattern.shape[0], BinaryPattern.shape[1]])\n",
    "#         accumulator.data += final_pattern\n",
    "#     average_final_pattern = accumulator / n_robustness\n",
    "    pattern.data = replace_nan_with_1(BinaryPattern)\n",
    "    eps_r = (pattern.squeeze(0).squeeze(0)*(eps_max - eps_min)) + eps_min\n",
    "#     eps_r = torch.clamp(eps_r,eps_min,eps_max)\n",
    "    loss_val,outputs,ER_t, UR_t,outputs = loss_func(eps_r)\n",
    "    loss_val.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "#     Gradient = (pattern.grad)\n",
    "\n",
    "    ############################################################################################################\n",
    "    #Back propagate gradient through robustness filters\n",
    "#     Gradient = gauss_grad_2d(Gradient, pad_to_size_with_zeros(filtered_pattern2, [N_x, N_y]), b_vector[iteration], threshold_vectors[robust_iter, iteration], BlurGrid)\n",
    "#     Gradient = filtered_grad_2d(Gradient, FilteredPattern, b_vector[iteration], 0.5, BlurGridLarge)\n",
    "    pattern.data = enforce_symmetry(pattern, asymmetry_x, asymmetry_y)\n",
    "    ############################################################################################################ \n",
    "    #Normalize gradient to step size\n",
    "#     CurrStepSize = (StepSize*StepDecline)**iteration;\n",
    "#     Gradient =  Gradient / torch.max(torch.abs(Gradient))\n",
    "#     ############################################################################################################\n",
    "    #Ensure final device will stay between 0 and 1\n",
    "    #Remove unusable terms from normalization\n",
    "#     mask1 = (Gradient + pattern) > 1\n",
    "#     Gradient[mask1] = 1 - pattern[mask1]\n",
    "#     mask2 = (Gradient + pattern) < 0\n",
    "#     Gradient[mask2] = -pattern[mask2]\n",
    "#     Gradient.data = CurrStepSize * Gradient \n",
    "#     Gradient.data = (Gradient/ torch.max(torch.abs(Gradient)))\n",
    "#     Gradient.data = torch.clamp(Gradient, min=-0.2, max=0.2)\n",
    "\n",
    "#     ############################################################################################################\n",
    "#     if Gradient is not None:\n",
    "#         print(\"pattern grad\", Gradient)\n",
    "#         pattern.data = torch.add(Gradient,pattern)\n",
    "#     else:\n",
    "#         print(\"pattern grad\", Gradient)\n",
    "    ############################################################################################################\n",
    "    pattern.data = torch.clamp(pattern, min=0, max=1)\n",
    "    ############################################################################################################\n",
    "    #Apply blur if necessary\n",
    "#     pattern.data = blur_geom_post_grad(pattern, iteration, opt_parm, dr,iteration_max)\n",
    "#     pattern.data = average_final_pattern.clone()\n",
    "    loss_mat.append(loss_val.item())\n",
    "    step.append(iteration)\n",
    "    plot_real_part_effective_permittivity_and_FOM_online(loss_mat, step, Lx,Ly, ER_t,str(iteration)+'.png',\n",
    "                                                         outputs)\n",
    "    print(f'Iteration: {iteration+1}/{iteration_max}, FOM: {loss_val.item()}')\n",
    "FilteredPattern = density_filter_2d(pattern, BlurGridLarge)\n",
    "BinaryPattern = thresh_filter(FilteredPattern, b_vector[iteration], 0.5)\n",
    "filtered_pattern2 = gauss_filter_2d(BinaryPattern, BlurGrid)\n",
    "FinalPattern = thresh_filter(FilteredPattern, b_vector[iteration], 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a2a638f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# #Main_Loop\n",
    "# ##################################################################################################\n",
    "# # Number of optimization iterations.\n",
    "# iteration_max = 20\n",
    "# bin_parm = {'Min': 1,'Max': 20.0,'IterationStart': 1,'IterationHold': 10}\n",
    "# b_vector = generate_bvector(iteration_max, bin_parm)\n",
    "# opt_parm = {'Optimization': {'Iterations': iteration_max,\n",
    "#         'Robustness': {'StartDeviation': [-5, 0, 5],# Starting edge deviation values\n",
    "#             'EndDeviation': [-5, 0, 5],# Ending edge deviation values\n",
    "#             'Ramp':2,#Iterations over which the thresholding parameter changes\n",
    "#             'Weights':[.5, 1, .5]},# Gradient weight for each robustness value\n",
    "#             'Filter': {'BlurRadius': 3}}}\n",
    "# threshold_vectors, n_robustness = generate_thresh_vectors(opt_parm)\n",
    "# ##################################################################################################\n",
    "# ##Optimization:\n",
    "# var_shape = (1)\n",
    "# desired_phase_1_num = 180\n",
    "# desired_amp_1 = 1\n",
    "# desired_phase_2_num = 270\n",
    "# desired_amp_2 = 1\n",
    "# ##################################################################################################\n",
    "# desired_phase_1 = desired_phase_1_num * np.ones(shape = var_shape)\n",
    "# desired_phase_1 = torch.tensor(desired_phase_1, dtype=torch.float32,requires_grad=True)\n",
    "# desired_phase_2 = desired_phase_2_num* np.ones(shape = var_shape)\n",
    "# desired_phase_2 = torch.tensor(desired_phase_2, dtype=torch.float32,requires_grad=True)\n",
    "# ##################################################################################################\n",
    "# plt.ion()\n",
    "# wavelength_list = np.arange(1550, 1551, 2)#[500]\n",
    "# params = solver.initialize_params(wavelengths =wavelength_list,\n",
    "#                                   thetas = [0.0 for i in wavelength_list],\n",
    "#                                   phis= [0.0 for i in wavelength_list],\n",
    "#                                   pte= [1.0 for i in wavelength_list],#put real small numer to avoid inf\n",
    "#                                   ptm= [1.0 for i in wavelength_list],   \n",
    "#                                   erd = 17.64-.0j, # Negative imaginary part convention for loss\n",
    "#                                   ers = 1.69 ,\n",
    "#                                   PQ = [7, 7],\n",
    "#                                   L = [ 300.0, 2500.0],\n",
    "#                                   Lx = 2000.0,\n",
    "#                                   Ly = 1000.0,\n",
    "#                                   Nx = 256,\n",
    "#                                   eps_max =16.4-.0j )\n",
    "# N_x = params[\"Nx\"]\n",
    "# N_y = int(np.round(params['Nx'] * params['Ly'] / params['Lx']))\n",
    "# eps_min = params['eps_min']\n",
    "# eps_max = params['eps_max']\n",
    "# asymmetry_x = True\n",
    "# asymmetry_y = True\n",
    "# grid = [N_x, N_x]\n",
    "# period = [params[\"Lx\"]*1e9, params[\"Ly\"]*1e9]\n",
    "# wavelength = wavelength_list[0]\n",
    "# x_grid, y_grid, dr = define_grid(grid, period, wavelength)\n",
    "# # Example\n",
    "# BlurGridLarge = 3\n",
    "# rand_parm = {\n",
    "#     'Pitch': 0.2,\n",
    "#     'Average': 0.5,\n",
    "#     'Sigma': .3\n",
    "# }\n",
    "# period_x = 1\n",
    "# period_y = 1\n",
    "\n",
    "# pattern = random_start(N_x, N_y, (period_x, period_y), rand_parm, asymmetry_x, asymmetry_y)\n",
    "# pattern = torch.nn.Parameter(pattern.to(\"cuda\"))  # Wrap eps_r with Parameter for optimization\n",
    "# pattern.requires_grad = True\n",
    "# Gradient = torch.zeros_like(pattern)\n",
    "# Gradient = torch.nn.Parameter(Gradient.to(\"cuda\"))  # Wrap eps_r with Parameter for optimization\n",
    "# Gradient.requires_grad = True\n",
    "# average_final_pattern = pattern.clone()\n",
    "# average_final_pattern = torch.nn.Parameter(average_final_pattern.to(\"cuda\"))  # Wrap eps_r with Parameter for optimization\n",
    "# average_final_pattern.requires_grad = True\n",
    "# # plt.imshow(pattern.cpu().detach())\n",
    "# # plt.show()\n",
    "# BlurGrid = 5;\n",
    "# ##################################################################################################\n",
    "# eps_r = generate_eps_r(N_x,N_y, eps_min, eps_max, asymmetry_x, asymmetry_y)\n",
    "# eps_r = torch.nn.Parameter(eps_r.to(\"cuda\"))  # Wrap eps_r with Parameter for optimization\n",
    "# Lx = params['Lx']\n",
    "# Ly = params['Ly']\n",
    "# eps_r_ref = generate_eps_r(N_x,N_y, eps_min, eps_min, asymmetry_x, asymmetry_y)\n",
    "# # Define an optimizer and data to be stored.\n",
    "# optimizer = optim.Adam([pattern], lr=3e-3)\n",
    "# StepSize = 1#  Initial gradient step size\n",
    "# StepDecline = 0.99 # Multiplying factor that decreases step size each iteration\n",
    "# loss = np.zeros(N)\n",
    "# step = []\n",
    "# loss_mat = []\n",
    "# #####################################################\n",
    "# fig = plt.figure(figsize=(16, 6))\n",
    "# pos0 = [0.06, 0.1, 0.28, 0.8]\n",
    "# pos1 = [0.38, 0.1, 0.28, 0.8]\n",
    "# pos2 = [0.715, 0.1, 0.28, 0.8]\n",
    "# axs0 = fig.add_axes(pos0)\n",
    "# axs1 = fig.add_axes(pos1)\n",
    "# axs2 = fig.add_axes(pos2)\n",
    "# ######################################################\n",
    "# # Optimize\n",
    "# final_pattern_mat = []\n",
    "# print('Optimizing...')\n",
    "# for iteration in range(iteration_max):\n",
    "#     optimizer.zero_grad()\n",
    "#     #First filter to enforce binarization\n",
    "#     FilteredPattern = density_filter_2d(pattern, BlurGridLarge)\n",
    "#     BinaryPattern = thresh_filter(FilteredPattern, b_vector[iteration], 0.5)#\n",
    "#     accumulator = torch.zeros_like(BinaryPattern)\n",
    "# #     # Begin robustness loop\n",
    "#     for robust_iter in range(n_robustness):\n",
    "#         # Second filter to model physical edge deviations\n",
    "#         filtered_pattern2 = gauss_filter_2d(BinaryPattern, BlurGrid)\n",
    "#         final_pattern = thresh_filter(filtered_pattern2, b_vector[iteration], threshold_vectors[robust_iter, iteration])\n",
    "#         final_pattern = pad_to_size_with_zeros(final_pattern, [BinaryPattern.shape[0], BinaryPattern.shape[1]])\n",
    "#         accumulator.data += final_pattern\n",
    "#     average_final_pattern = accumulator / n_robustness\n",
    "#     pattern.data = replace_nan_with_1(BinaryPattern)\n",
    "#     eps_r = (pattern.squeeze(0).squeeze(0)*(eps_max - eps_min)) + eps_min\n",
    "# #     eps_r = torch.clamp(eps_r,eps_min,eps_max)\n",
    "#     loss_val,outputs,ER_t, UR_t,outputs = loss_func(eps_r)\n",
    "#     loss_val.backward()\n",
    "#     optimizer.step()\n",
    "#     Gradient = (pattern.grad)\n",
    "#     ############################################################################################################\n",
    "#     #Back propagate gradient through robustness filters\n",
    "# #     Gradient = gauss_grad_2d(Gradient, pad_to_size_with_zeros(filtered_pattern2, [N_x, N_y]), b_vector[iteration], threshold_vectors[robust_iter, iteration], BlurGrid)\n",
    "# #     Gradient = filtered_grad_2d(Gradient, FilteredPattern, b_vector[iteration], 0.5, BlurGridLarge)\n",
    "#     Gradient.data = enforce_symmetry(Gradient, asymmetry_x, asymmetry_y)\n",
    "#     ############################################################################################################ \n",
    "#     #Normalize gradient to step size\n",
    "# #     CurrStepSize = (StepSize*StepDecline)**iteration;\n",
    "# #     Gradient =  Gradient / torch.max(torch.abs(Gradient))\n",
    "# #     ############################################################################################################\n",
    "#     #Ensure final device will stay between 0 and 1\n",
    "#     #Remove unusable terms from normalization\n",
    "# #     mask1 = (Gradient + pattern) > 1\n",
    "# #     Gradient[mask1] = 1 - pattern[mask1]\n",
    "# #     mask2 = (Gradient + pattern) < 0\n",
    "# #     Gradient[mask2] = -pattern[mask2]\n",
    "# #     Gradient.data = CurrStepSize * Gradient \n",
    "# #     Gradient.data = (Gradient/ torch.max(torch.abs(Gradient)))\n",
    "# #     Gradient.data = torch.clamp(Gradient, min=-0.2, max=0.2)\n",
    "\n",
    "# #     ############################################################################################################\n",
    "#     if Gradient is not None:\n",
    "# #         print(\"pattern grad\", Gradient)\n",
    "#         pattern.data = torch.add(Gradient,pattern)\n",
    "#     else:\n",
    "#         print(\"pattern grad\", Gradient)\n",
    "#     ############################################################################################################\n",
    "#     pattern.data = torch.clamp(pattern, min=0, max=1)\n",
    "#     ############################################################################################################\n",
    "#     #Apply blur if necessary\n",
    "# #     pattern.data = blur_geom_post_grad(pattern, iteration, opt_parm, dr,iteration_max)\n",
    "# #     pattern.data = average_final_pattern.clone()\n",
    "#     loss_mat.append(loss_val.item())\n",
    "#     step.append(iteration)\n",
    "#     plot_real_part_effective_permittivity_and_FOM_online(loss_mat, step, Lx,Ly, ER_t,str(iteration)+'.png',\n",
    "#                                                          outputs)\n",
    "#     print(f'Iteration: {iteration+1}/{iteration_max}, FOM: {loss_val.item()}')\n",
    "# FilteredPattern = density_filter_2d(pattern, BlurGridLarge)\n",
    "# BinaryPattern = thresh_filter(FilteredPattern, b_vector[iteration], 0.5)\n",
    "# filtered_pattern2 = gauss_filter_2d(BinaryPattern, BlurGrid)\n",
    "# FinalPattern = thresh_filter(FilteredPattern, b_vector[iteration], 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863e4b93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee757980",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T17:34:45.437168Z",
     "start_time": "2023-09-24T17:34:42.771356Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:8: SyntaxWarning: invalid escape sequence '\\H'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\H'\n",
      "C:\\Users\\jchang427\\AppData\\Local\\Temp\\ipykernel_10052\\3849398106.py:8: SyntaxWarning: invalid escape sequence '\\H'\n",
      "  wavelengths, n_values, k_values = read_material_file('material\\HamedAbr-TiO2 (1).csv')#AM_SB2_S3.txt')\n",
      "c:\\Users\\jchang427\\Downloads\\ToJiu\\solver.py:1316: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  k0 = torch.tensor(2 * np.pi / params['lam0'], dtype = torch.cfloat).clone().detach().to(torch.cfloat).to(\"cuda\")\n",
      "c:\\Users\\jchang427\\Downloads\\ToJiu\\solver.py:1317: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kinc_x0 = torch.tensor(n1 * torch.sin(params['theta']) * torch.cos(params['phi'])\n",
      "c:\\Users\\jchang427\\Downloads\\ToJiu\\solver.py:1319: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kinc_y0 = torch.tensor(n1 * torch.sin(params['theta']) * torch.sin(params['phi'])\n",
      "c:\\Users\\jchang427\\Downloads\\ToJiu\\solver.py:1321: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kinc_z0 = torch.tensor(n1 * torch.cos(params['theta']), dtype = torch.cfloat).to(\"cuda\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulating wavelength: 1530\n",
      "simulating wavelength: 1536\n",
      "simulating wavelength: 1542\n",
      "simulating wavelength: 1548\n",
      "simulating wavelength: 1554\n",
      "simulating wavelength: 1560\n",
      "simulating wavelength: 1566\n",
      "TM_phase: [-1.64539313 -1.57854712 -1.44296479 -1.41929734 -1.36895394 -1.31210911\n",
      " -1.25371456]\n",
      "TE_phase: [1.91210258 2.00800705 1.77154422 1.9652158  2.0735395  2.15944672\n",
      " 2.23870325]\n",
      "TM_amp: [0.55187553 0.58416706 0.56065983 0.53500021 0.54411608 0.55380237\n",
      " 0.56373   ]\n",
      "TE_amp: [0.5168063  0.43790001 0.47294289 0.61001998 0.61953729 0.62375897\n",
      " 0.62748379]\n"
     ]
    }
   ],
   "source": [
    "def Spectrum_phase_amp(ER_t, UR_t,delta,start_wavelength,end_wavelength):\n",
    "    relative_Transmission_mat = []\n",
    "    relative_Phase_delay_mat = []\n",
    "    wavelength_mat = []\n",
    "    epsilon_mat = []\n",
    "    thetas_mat = []\n",
    "    stepnum = int((end_wavelength-start_wavelength)/delta)+1\n",
    "    wavelengths, n_values, k_values = read_material_file('material\\HamedAbr-TiO2 (1).csv')#AM_SB2_S3.txt')\n",
    "    for i in range (0,stepnum):\n",
    "        wavelength = start_wavelength+i*delta\n",
    "        n, k, epsilon = interpolate_material(wavelengths, n_values, k_values, wavelength*1e-3)\n",
    "        wavelength_mat.append(wavelength)\n",
    "        epsilon_mat.append(np.conj(epsilon))\n",
    "        thetas_mat.append(0.0)\n",
    "    for i in range (0,stepnum):\n",
    "        params = solver.initialize_params(wavelengths = [wavelength_mat[i]],   \n",
    "                                      thetas = [0.0 for i in wavelength_list],\n",
    "                                      phis= [0.0 for i in wavelength_list],\n",
    "                                      pte= [1.0 for i in wavelength_list],#put real small numer to avoid inf\n",
    "                                      ptm= [1.0 for i in wavelength_list],\n",
    "                                      erd=[epsilon_mat[i]],ers=1.69, PQ=[7, 7],\n",
    "                                      L = [ 300.0, 2500.0],\n",
    "                                      Lx = 2000.0,\n",
    "                                      Ly = 500.0,\n",
    "                                      Nx = 256)\n",
    "        loss_step,relative_Transmission,relative_Phase_delay,ER_t, UR_t = loss_func_spec(ER_t, UR_t,params,desired_phase_1,desired_phase_2,transmitted_field_ref)\n",
    "        relative_Transmission_mat.append(relative_Transmission.cpu().detach())\n",
    "        relative_Phase_delay_mat.append(relative_Phase_delay.cpu().detach())\n",
    "        if i%1 == 0:\n",
    "            print(\"simulating wavelength:\",wavelength_mat[i])\n",
    "#             print(\"simulating epsilon:\",epsilon_mat[i])\n",
    "    relative_Transmission_mat = [tensor.numpy() for tensor in relative_Transmission_mat]\n",
    "    relative_Phase_delay_mat = [tensor.numpy() for tensor in relative_Phase_delay_mat]\n",
    "    wavelength_mat = np.array(wavelength_mat)\n",
    "    # Initialize empty arrays for TM and TE\n",
    "    TM_phase = np.empty(len(relative_Phase_delay_mat))\n",
    "    TE_phase = np.empty(len(relative_Phase_delay_mat))\n",
    "    \n",
    "    # Iterate through the array and extract the first and second elements\n",
    "    for i, tensor_element in enumerate(relative_Phase_delay_mat):\n",
    "        TM_phase[i] = tensor_element[0]\n",
    "        TE_phase[i] = tensor_element[1]\n",
    "    \n",
    "    # Now, TM and TE contain the first and second elements, respectively\n",
    "    print(\"TM_phase:\", TM_phase)\n",
    "    print(\"TE_phase:\", TE_phase)\n",
    "    ####################################################\n",
    "    # Initialize empty arrays for TM and TE\n",
    "    TM_amp = np.empty(len(relative_Transmission_mat))\n",
    "    TE_amp = np.empty(len(relative_Transmission_mat))\n",
    "    \n",
    "    # Iterate through the array and extract the first and second elements\n",
    "    for i, tensor_element in enumerate(relative_Transmission_mat):\n",
    "        TM_amp[i] = tensor_element[0]\n",
    "        TE_amp[i] = tensor_element[1]\n",
    "    \n",
    "    # Now, TM and TE contain the first and second elements, respectively\n",
    "    print(\"TM_amp:\", TM_amp)\n",
    "    print(\"TE_amp:\", TE_amp)\n",
    "    return TM_amp,TE_amp,TM_phase,TE_phase,wavelength_mat,ER_t\n",
    "############################################################################\n",
    "#######Initialize grating duty cycle variable.\n",
    "delta = 1*(5)+1\n",
    "start_wavelength = 1530# 375\n",
    "end_wavelength = 1570# 750\n",
    "TM_amp,TE_amp,TM_phase,TE_phase,wavelength_mat,ER_t = Spectrum_phase_amp(ER_t, UR_t,delta,start_wavelength,end_wavelength)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8dc25c5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T17:26:44.285627Z",
     "start_time": "2023-09-24T17:26:43.848820Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:26: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:26: SyntaxWarning: invalid escape sequence '\\l'\n",
      "C:\\Users\\jchang427\\AppData\\Local\\Temp\\ipykernel_10052\\1047746932.py:7: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  axes[0].set_xlabel('$\\lambda_{\\mu m}$', fontsize=16)\n",
      "C:\\Users\\jchang427\\AppData\\Local\\Temp\\ipykernel_10052\\1047746932.py:26: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  axes[1].set_xlabel('$\\lambda_{\\mu m}$', fontsize=16)\n"
     ]
    }
   ],
   "source": [
    "def plot_polarizations(wavelength_mat, TM_amp, TM_phase, TE_amp, TE_phase,file_name):\n",
    "    # Create the 2x1 subplot\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "    # Plot TM polarization in the upper subplot\n",
    "    axes[0].plot(wavelength_mat * 1e-3, TM_amp, 'k-', label='TM Relative Transmission', linewidth=4)\n",
    "    axes[0].set_xlabel('$\\lambda_{\\mu m}$', fontsize=16)\n",
    "    axes[0].set_ylabel('Transmission', fontsize=16)\n",
    "    axes[0].set_title('Transmission and Phase vs Wavelength for TM Polarization', fontsize=18)\n",
    "    axes[0].set_yticks([0, 1])\n",
    "    axes[0].legend(loc='upper right', fontsize=14)\n",
    "    axes[0].set_xlim(wavelength_mat[0]/1000,wavelength_mat[-1]/1000)\n",
    "#     axes[0].grid(True)\n",
    "\n",
    "    # Create a second y-axis on the right for TM phase delay\n",
    "    ax2 = axes[0].twinx()\n",
    "    ax2.plot(wavelength_mat * 1e-3, TM_phase, 'r-', label='TM Relative Phase Delay', linewidth=4)\n",
    "    ax2.set_ylabel('TM Phase Delay', color='r', fontsize=16)\n",
    "    ax2.tick_params(axis='y', labelcolor='r')\n",
    "    ax2.set_yticks([-np.pi, -np.pi / 2, 0, np.pi / 2, np.pi])\n",
    "    ax2.set_yticklabels(['$-π$', '$-π/2$', '0', '$π/2$', '$π$'], fontsize=14)\n",
    "    ax2.set_xlim(wavelength_mat[0]/1000,wavelength_mat[-1]/1000)\n",
    "\n",
    "    # Plot TE polarization in the lower subplot\n",
    "    axes[1].plot(wavelength_mat * 1e-3, TE_amp, 'g-', label='TE Relative Transmission', linewidth=4)\n",
    "    axes[1].set_xlabel('$\\lambda_{\\mu m}$', fontsize=16)\n",
    "    axes[1].set_ylabel('Transmission', fontsize=16)\n",
    "    axes[1].set_title('Transmission and Phase vs Wavelength for TE Polarization', fontsize=18)\n",
    "    axes[1].set_yticks([0, 1])\n",
    "    axes[1].legend(loc='upper right', fontsize=14)\n",
    "    axes[1].set_xlim(wavelength_mat[0]/1000,wavelength_mat[-1]/1000)\n",
    "#     axes[1].grid(True)\n",
    "\n",
    "    # Create a second y-axis on the right for TE phase delay\n",
    "    ax3 = axes[1].twinx()\n",
    "    ax3.plot(wavelength_mat * 1e-3, TE_phase, 'y-', label='TE Relative Phase Delay', linewidth=4)\n",
    "    ax3.set_ylabel('TE Phase Delay', color='y', fontsize=16)\n",
    "    ax3.tick_params(axis='y', labelcolor='y')\n",
    "    ax3.set_yticks([-np.pi, -np.pi / 2, 0, np.pi / 2, np.pi])\n",
    "    ax3.set_yticklabels(['$-π$', '$-π/2$', '0', '$π/2$', '$π$'], fontsize=14)\n",
    "    ax3.set_xlim(wavelength_mat[0]/1000,wavelength_mat[-1]/1000)\n",
    "\n",
    "    # Save the plot as a PDF file\n",
    "    plt.savefig('images/'+file_name+'.pdf', bbox_inches='tight')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot the data\n",
    "plot_polarizations(wavelength_mat, TM_amp, TM_phase, TE_amp, TE_phase,'relative_transmission_phase_delay')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "633a669b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T17:21:42.924780Z",
     "start_time": "2023-09-24T17:21:40.017926Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jchang427\\Downloads\\ToJiu\\solver.py:1316: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  k0 = torch.tensor(2 * np.pi / params['lam0'], dtype = torch.cfloat).clone().detach().to(torch.cfloat).to(\"cuda\")\n",
      "c:\\Users\\jchang427\\Downloads\\ToJiu\\solver.py:1317: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kinc_x0 = torch.tensor(n1 * torch.sin(params['theta']) * torch.cos(params['phi'])\n",
      "c:\\Users\\jchang427\\Downloads\\ToJiu\\solver.py:1319: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kinc_y0 = torch.tensor(n1 * torch.sin(params['theta']) * torch.sin(params['phi'])\n",
      "c:\\Users\\jchang427\\Downloads\\ToJiu\\solver.py:1321: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kinc_z0 = torch.tensor(n1 * torch.cos(params['theta']), dtype = torch.cfloat).to(\"cuda\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulating wavelength: 1530\n",
      "simulating wavelength: 1536\n",
      "simulating wavelength: 1542\n",
      "simulating wavelength: 1548\n",
      "simulating wavelength: 1554\n",
      "simulating wavelength: 1560\n",
      "simulating wavelength: 1566\n",
      "TM_phase: [1.46170449 1.40300643 1.33610821 1.26115489 1.17767882 1.08623123\n",
      " 0.9875133 ]\n",
      "TE_phase: [-2.97318482 -3.05246568 -3.13144112  3.07330513  2.9957757   2.91922903\n",
      "  2.84373426]\n",
      "TM_amp: [0.0042106  0.00499098 0.00592384 0.00702088 0.00828458 0.00970612\n",
      " 0.01126155]\n",
      "TE_amp: [0.00669449 0.00716773 0.00764014 0.00810838 0.00857357 0.00903607\n",
      " 0.00949911]\n"
     ]
    }
   ],
   "source": [
    "def apply_threshold(ER_t, threshold, eps_min, eps_max):\n",
    "    # Split the complex tensor into real and imaginary parts\n",
    "    ER_real = ER_t.real.to(\"cpu\")\n",
    "    ER_imag = ER_t.imag.to(\"cpu\")\n",
    "\n",
    "    # Apply the thresholding condition\n",
    "    binary_ER_real = torch.where(ER_real < threshold, eps_min, eps_max)\n",
    "    binary_ER_imag = torch.where(ER_imag < threshold, eps_min, eps_max)\n",
    "\n",
    "    # Combine the thresholded real and imaginary parts\n",
    "    binary_ER_t = binary_ER_real + 1j * binary_ER_imag\n",
    "\n",
    "    return binary_ER_t\n",
    "\n",
    "\n",
    "threshold = 8  # Set the threshold value\n",
    "eps_min = params['eps_min']   # Minimum value for thresholding\n",
    "eps_max = params['eps_max']  # Maximum value for thresholding\n",
    "binary_ER_t = apply_threshold(ER_t, threshold, eps_min, eps_max)\n",
    "plot_real_part_effective_permittivity(Lx,binary_ER_t, 'refIndex.png')\n",
    "plt.figure()\n",
    "plotter_iteration(loss_mat, step, 'FOM', 'images/Reflection.pdf', color='blue')\n",
    "TM_amp,TE_amp,TM_phase,TE_phase,wavelength_mat,ER_t = Spectrum_phase_amp(binary_ER_t, UR_t,delta,start_wavelength,end_wavelength)\n",
    "plot_polarizations(wavelength_mat, TM_amp, TM_phase, TE_amp, TE_phase,'Binary_relative_transmission_phase_delay')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b7121ac0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T16:56:13.744251Z",
     "start_time": "2023-09-24T16:56:08.707158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF saved at output.gif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import imageio\n",
    "\n",
    "# Path to the directory containing the images\n",
    "image_directory = \"C:\\\\Users\\\\jchang427\\\\Downloads\\\\ToJiu\\\\images\"\n",
    "\n",
    "# List all image files in the directory\n",
    "image_files = [file for file in os.listdir(image_directory) if file.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Sort the image files to ensure correct order\n",
    "image_files.sort()\n",
    "\n",
    "# Load images and append to a list\n",
    "images = []\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(image_directory, image_file)\n",
    "    image = Image.open(image_path)\n",
    "    images.append(image)\n",
    "\n",
    "# Output GIF file path\n",
    "gif_output_path = 'output.gif'\n",
    "\n",
    "# Save the images as a GIF using imageio\n",
    "imageio.mimsave(gif_output_path, images, duration=0.5)  # You can adjust the duration between frames\n",
    "\n",
    "print(f'GIF saved at {gif_output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03089238",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bba5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "309f8e95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T16:56:18.866088Z",
     "start_time": "2023-09-24T16:56:16.907910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at output_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Path to the directory containing the images\n",
    "image_directory = r'.\\\\images_opt'\n",
    "\n",
    "# List all image files in the directory\n",
    "image_files = [file for file in os.listdir(image_directory) if file.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Sort the image files to ensure correct order\n",
    "image_files.sort()\n",
    "\n",
    "# Get the dimensions of the first image\n",
    "first_image_path = os.path.join(image_directory, image_files[0])\n",
    "first_image = cv2.imread(first_image_path)\n",
    "height, width, layers = first_image.shape\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "video_output_path = 'output_video.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Use 'XVID' for AVI format\n",
    "out = cv2.VideoWriter(video_output_path, fourcc, 10, (width, height))  # Adjust frame rate as needed\n",
    "\n",
    "# Write each image to the video\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(image_directory, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "    out.write(image)\n",
    "\n",
    "# Release the VideoWriter object and close the video file\n",
    "out.release()\n",
    "\n",
    "print(f'Video saved at {video_output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aede296f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
